{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a string into a list of lower-cased, deaccented tokens.\n",
    "[Gensim preprocess method](https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html)\n",
    "Input: a string\n",
    "\n",
    "Output: a list of  tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "text = [\"john saw the cat near john\",\"john saw the dog\"]\n",
    "\n",
    "def sent_to_words(text):   \n",
    "    return [gensim.utils.simple_preprocess(str(sentence), deacc=True) for sentence in text]  \n",
    "    # deacc=True removes accents\n",
    "    \n",
    "# print out the tokens\n",
    "tokens = sent_to_words(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use Gensim [dictionary method](https://www.tutorialspoint.com/gensim/gensim_creating_a_dictionary.htm) to create a dictionary\n",
    "\n",
    "TOKEN -> IDENTIFIER\n",
    "\n",
    "* the dictionary maps each token in the corpus to an integer \n",
    "* this integer is then used as an identifier for that token\n",
    "* Gensim uses the identifier rather than the tokens to build the document/tokens matrix and the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# the input must be a list of lists of tokens\n",
    "tokens = [['john', 'saw', 'the', 'cat', 'near', 'john'], ['john', 'saw', 'the', 'dog']]\n",
    "\n",
    "# Create the word2id dictionary which maps each token to an integer (an identifier)\n",
    "dic = corpora.Dictionary(tokens)\n",
    "\n",
    "# How many tokens ?\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dictionary\n",
    "print(dic.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a document/token matrix\n",
    "\n",
    "Using Gensim [doc2bow method](https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.doc2bow.html) (from Corpora module) to convert a list of lists of tokens to a document/token matrix, a list of (token_id, token_count) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to document/token matrix\n",
    "doc_token_matrix = [dic.doc2bow(text) for text in tokens]\n",
    "\n",
    "# The output matrix indicates for each input document the frequency of the tokens contained in that document \n",
    "print(doc_token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc0: ['john', 'saw', 'the', 'cat', 'near', 'john']\n",
    "# token2id dictionary: {'cat': 0, 'john': 1, 'near': 2, 'saw': 3, 'the': 4, 'dog': 5}\n",
    "\n",
    "# Get the document vector for doc0\n",
    "print(doc_token_matrix[0])\n",
    "\n",
    "# Result: [(0, 1), (1, 2), (2, 1), (3, 1), (4, 1)]\n",
    "# if we replace the identifiers by their corresponding tokens we get the following frequency vector for doc0\n",
    "# [('cat', 1), ('john', 2), ('near', 1), ('saw', 1), ('the', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LDA model\n",
    "* input the document matrix and the word2id dictionary\n",
    "* Read the [doc](https://radimrehurek.com/gensim/models/ldamodel.html) to understand the options\n",
    "* id2word will create the inverse mapping from the word2id dictionary\n",
    "    * the word2id dictionary maps a token to an integer which is used as its identifier   \n",
    "    TOKEN -> ID\n",
    "    * conversely id2word is a dictionary mapping a token identifier to the corresponding token   \n",
    "    ID -> TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=doc_token_matrix,\n",
    "                                       id2word=dic,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the token whose identifier is 3\n",
    "lda_model.id2word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the identifier for the token \"near\"\n",
    "dic.token2id['near']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print Document/Token vector for the first document in the document/token matrix\n",
    "print(doc_token_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# John saw the cat near John\n",
    "# {'cat': 0, 'john': 1, 'near': 2, 'saw': 3, 'the': 4, 'dog': 5}\n",
    "# [(0, 1), (1, 2), (2, 1), (3, 1), (4, 1)]\n",
    "# < cat:1, john:2, near:1, saw:1,the:1 >\n",
    "\n",
    "for i,j in doc_token_matrix[0]:\n",
    "    token = lda_model.id2word[i]\n",
    "    print (token,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the keywords for each topic and the weight of each keyword for that topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keywords in the 10 topics\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing  Coherence Scores\n",
    "\n",
    "Coherence measures score a topic by measuring the degree of semantic similarity between high scoring words in the topic.\n",
    "* C_v measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
    "* C_p is based on a sliding window, one-preceding segmentation of the top words and the confirmation measure of Fitelson's coherence\n",
    "* C_uci measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
    "* C_umass is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
    "* C_npmi is an enhanced version of the C_uci coherence using the normalized pointwise mutual information (NPMI)\n",
    "* C_a is based on a context window, a pairwise comparison of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokens, dictionary=dic, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
