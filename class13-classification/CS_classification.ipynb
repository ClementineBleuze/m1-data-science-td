{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorizing the data**\n",
    "- Input: data (typically a list of texts or sentences\n",
    "- Output:  a matrix of size (m,n) with m the number of data instances and n the nb of features (typically the corpus tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TFIDF vectorizer to convert convert words to Vector Space\n",
    "vectorizer = TfidfVectorizer(max_features=8000, use_idf=True, stop_words='english', tokenizer=nltk.word_tokenize, ngram_range=(1, 3))\n",
    "\n",
    "# Fit the vectorizer to train and test data\n",
    "# fit_transform computes the scaling parameters (mu, rho) on the training data and scales \n",
    "# the training data.\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "# transform scales the test data using the scaling parameters computed on the training data.\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing out the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and testing a classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Create an object of the class *Perceptron*\n",
    "clf = Perceptron()\n",
    "\n",
    "# Learn/train  the model\n",
    "# The model is trained on (input,output) pairs \n",
    "# Input:  X_train_vec (the vectorized input texts) \n",
    "# Output: y_train (the labels)\n",
    "clf.fit( X_train_vec, y_train )\n",
    "\n",
    "# Predict the labels of the test instances\n",
    "y_pred = clf.predict( X_test_vec )\n",
    "\n",
    "# Print the gold and predicted labels\n",
    "# the gold labels come from the dataset (these are the classes associated with each input)\n",
    "print( \"y true:\", Y_test )\n",
    "# the predicted labels are produced by the classifier\n",
    "print( \"y pred:\", y_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating a classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Print the accuracy\n",
    "print( \"Acc:\", accuracy_score(Y_test, y_pred ) )\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification report:', classification_report(Y_test, y_pred ))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion matrix:', confusion_matrix(Y_test, y_pred ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vocabulary into a variable\n",
    "vocab = vectorizer.vocabulary_\n",
    "print( \"Vocabulary size:\", len(vocab) )\n",
    "\n",
    "\n",
    "ix_to_tokens = { v:k for k,v in vocab.items() }\n",
    "\n",
    "# Save the weights in a dict key = index, value = weight\n",
    "features_weights = {i:w for (i,w) in enumerate( clf.coef_[0] ) }\n",
    "\n",
    "# Sort and print the list of weights\n",
    "sorted_weights = sort_dict(features_weights)\n",
    "print( sorted_weights )\n",
    "\n",
    "# Reverse dictionnaries for labels and vocabulary\n",
    "# tag_to_idx = {class_name:class_idx,} e.g. {drama:1,comedy:0}\n",
    "ix_to_tag = { v:k for k,v in tag_to_ix.items() }\n",
    "\n",
    "# Look at the best features for each class\n",
    "print( '\\nBest features for identifying class 1, ie', ix_to_tag[1])\n",
    "print( '\\n'.join( [':'.join( (ix_to_tokens[i],str(w)) )for (w,i) in reversed( sorted_weights[-6:] )] ) )\n",
    "\n",
    "print( '\\nBest features for identifying class 0, ie', ix_to_tag[0])\n",
    "print( '\\n'.join( [':'.join( (ix_to_tokens[i],str(w)) ) for (w,i) in sorted_weights[:6]] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**\n",
    "\n",
    "The Chi-square test is used in statistics to test the independence of two events. In feature selection, we use it to test whether the occurrence of a specific term and the occurrence of a specific class are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# N features with highest chi-squared statistics are selected\n",
    "chi2_features = SelectKBest(chi2, k = can be any number)\n",
    "X = chi2_features.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(chi2, k=5000)  # feature selection\n",
    "sel.fit(X_train,y_train)\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SKLearn pipeline object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),  # feature extraction\n",
    "    ('sel', SelectKBest(chi2, k=5000)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "classifier = pipeline.fit(x_train,y_train)\n",
    "predictions = classifier.predict(x_test)\n",
    "correct = 0\n",
    "for prediction,true_label in zip(predictions, y_test):\n",
    "    if prediction==true_label:\n",
    "        correct += 1\n",
    "print(correct/len(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
