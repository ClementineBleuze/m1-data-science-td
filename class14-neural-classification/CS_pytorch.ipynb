{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Cheatsheet\n",
    "\n",
    "[Pytorch Documentation](https://pytorch.org/docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install torch==2.0.0 torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Torch tensor\n",
    "elements = [[1, 2, 3], \n",
    "            [4, 5, 6]]\n",
    "t = torch.Tensor(elements)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a matrix filled zeros and of dtype long:\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0528, -0.0225, -0.7702],\n",
       "        [-1.1994,  0.1754, -0.0061],\n",
       "        [-0.2733,  1.1535,  1.8019]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor from normal distribution randoms\n",
    "t = torch.randn(3, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " 'torch.LongTensor')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "# a. fill it with zeros the values of \"elements\" above\n",
    "# b. Set the tensor to type 'long'\n",
    "x = torch.LongTensor(elements).long()\n",
    "x, x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor indexing: extract the value of the first row and second column of the tensor\n",
    "x[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor indexing: extract the first row of the tensor\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: \t\t torch.Size([3, 4, 2])\n",
      "Number of dimensions: \t 3\n",
      "Tensor type: \t\t torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Some tensor info\n",
    "# a. create a tensor of size 3,4,2 filled with random values drawn from normal distribution\n",
    "t = torch.randn(3, 4, 2)\n",
    "# b. getting some information about the created tensor\n",
    "print('Tensor shape: \\t\\t', t.shape)       # Note: t.size() gives the same\n",
    "print('Number of dimensions: \\t', t.dim()) # number of dimensions the tensor has\n",
    "print('Tensor type: \\t\\t', t.type())       # Note: there are other types (https://pytorch.org/docs/2.0/tensors.html?highlight=tensor+types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor dtype: \t\t torch.float32\n",
      "Device tensor on: \t cpu\n",
      "Tensor layout: \t\t torch.strided\n",
      "Number of elements: \t 24\n"
     ]
    }
   ],
   "source": [
    "# c. more methods to get information about the created tensor\n",
    "print('Tensor dtype: \\t\\t', t.dtype)       # type of the data contained within the tensor.\n",
    "print('Device tensor on: \\t', t.device)    # where tensor computations will be performed (CPU or GPU)\n",
    "print('Tensor layout: \\t\\t', t.layout)     # how the tensor is stored in memory\n",
    "print('Number of elements: \\t', t.numel()) # number of elements contained within the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshaping Tensors**\n",
    "\n",
    "Reshaping changes the tensor's shape but not the underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7397, -0.1561,  0.0840,  0.8304],\n",
       "         [ 1.1975, -0.4931,  1.3313, -2.1158],\n",
       "         [ 0.7900, -0.2853, -1.1461,  0.0483]]),\n",
       " 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of size (3,4) with random values\n",
    "t = torch.randn(3, 4)\n",
    "t, t.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7397, -0.1561,  0.0840,  0.8304,  1.1975, -0.4931],\n",
       "         [ 1.3313, -2.1158,  0.7900, -0.2853, -1.1461,  0.0483]]),\n",
       " 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape from (3,4) to (2,6). new shape must give same numel as initial\n",
    "t_26 = t.reshape([2,6])\n",
    "t_26, t_26.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7397, -0.1561],\n",
       "         [ 0.0840,  0.8304],\n",
       "         [ 1.1975, -0.4931],\n",
       "         [ 1.3313, -2.1158],\n",
       "         [ 0.7900, -0.2853],\n",
       "         [-1.1461,  0.0483]]),\n",
       " 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape from (3,4) to (6,2)\n",
    "t_62 = t.reshape([6,2])\n",
    "t_62, t_62.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7397, -0.1561,  0.0840,  0.8304],\n",
       "        [ 1.1975, -0.4931,  1.3313, -2.1158],\n",
       "        [ 0.7900, -0.2853, -1.1461,  0.0483]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape from (3,4) to (3,4). nothing changes\n",
    "t.reshape([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7397, -0.1561,  0.0840],\n",
       "         [ 0.8304,  1.1975, -0.4931]],\n",
       "\n",
       "        [[ 1.3313, -2.1158,  0.7900],\n",
       "         [-0.2853, -1.1461,  0.0483]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape with an added dimension \n",
    "t.reshape(2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resizing using torch.view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)   \n",
    "y = x.view(16)          # change tensor of size (4,4) to tensor of size (16)\n",
    "z = x.view(-1, 8)       # Note: the size where -1 is, is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View again...\n",
    "x = t.view(6,2)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7397, -0.1561],\n",
       "         [ 0.0840,  0.8304]],\n",
       "\n",
       "        [[ 1.1975, -0.4931],\n",
       "         [ 1.3313, -2.1158]],\n",
       "\n",
       "        [[ 0.7900, -0.2853],\n",
       "         [-1.1461,  0.0483]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(3, 2, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7397, -0.1561],\n",
       "        [ 0.0840,  0.8304],\n",
       "        [ 1.1975, -0.4931],\n",
       "        [ 1.3313, -2.1158],\n",
       "        [ 0.7900, -0.2853],\n",
       "        [-1.1461,  0.0483]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(6, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Squeezing and unsqueezing**\n",
    "\n",
    "* Squeezing a tensor removes the dimensions or axes that have a length of one.\n",
    "* Unsqueezing a tensor adds a dimension with a length of one.\n",
    "* These functions allow us to expand or shrink the rank (number of dimensions) of our tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "tensor([-0.7397, -0.1561,  0.0840,  0.8304,  1.1975, -0.4931,  1.3313, -2.1158,\n",
      "         0.7900, -0.2853, -1.1461,  0.0483])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape([1,12]).shape)\n",
    "print(t.reshape([1,12]).squeeze())\n",
    "print(t.reshape([1,12]).squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = torch.randn(3,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 3])\n",
      "torch.Size([3, 2, 1, 3])\n",
      "torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())\n",
    "y3 = y.unsqueeze(2)\n",
    "print(y3.size())\n",
    "print(y3.squeeze().size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([3, 2])\n",
      "Y shape:  torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6847, -0.4057],\n",
       "         [-1.5375,  0.4401],\n",
       "         [-0.3087, -0.0034]]),\n",
       " tensor([[ 0.6847, -1.5375, -0.3087],\n",
       "         [-0.4057,  0.4401, -0.0034]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,2)\n",
    "y = x.transpose(0, 1)\n",
    "print('X shape: ', x.shape)\n",
    "print('Y shape: ', y.shape)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting**\n",
    "\n",
    "See [pytorch 2.0.0 documentation](http://pytorch.org/docs/0.3.1/notes/broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  torch.Size([3, 1])\n",
      "Y shape:  torch.Size([3, 2])\n",
      "tensor([[0.9411],\n",
      "        [0.8422],\n",
      "        [0.9816]])\n",
      "tensor([[0.7207, 0.0050],\n",
      "        [0.2998, 0.8244],\n",
      "        [0.8220, 0.1230]])\n",
      "tensor([[1.6618, 0.9462],\n",
      "        [1.1420, 1.6667],\n",
      "        [1.8036, 1.1047]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# broadcasting\n",
    "x = torch.rand(3, 1)\n",
    "y = torch.rand(3, 2)\n",
    "print('X shape: ', x.shape)\n",
    "print('Y shape: ', y.shape) # Notice that x's dimension 1 (aka 2nd dim, aka last dim) is of size 1, while y's is of size 2\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y)\n",
    "print(torch.equal(x+y, y+x)) # check equality of 2 tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Tensor Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6203, 0.4387, 0.5037],\n",
       "        [0.4763, 0.2250, 0.2514],\n",
       "        [0.2042, 0.2217, 0.2593]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute matrix product\n",
    "x = torch.rand(3, 2)\n",
    "y = torch.rand(2, 3)\n",
    "x.matmul(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of x.bmm(y) operation:  tensor([[[0.2272, 0.3952, 0.6442],\n",
      "         [0.0824, 0.1391, 0.2336],\n",
      "         [0.2350, 0.4159, 0.6666]],\n",
      "\n",
      "        [[1.1697, 1.0601, 0.6435],\n",
      "         [1.3658, 1.1937, 0.8389],\n",
      "         [0.4688, 0.3894, 0.3283]]])\n",
      "Check equality:  True\n"
     ]
    }
   ],
   "source": [
    "# Compute batch matrix product\n",
    "# a. in x and y below think of the first dim (where size is both 2) as the batch size \n",
    "x = torch.rand(2, 3, 2)\n",
    "y = torch.rand(2, 2, 3)\n",
    "\n",
    "# b. torch.bmm() will do matrix product between each element of the batch in x and y\n",
    "xy = x.bmm(y)\n",
    "print(\"Result of x.bmm(y) operation: \", xy) # Note: same semantics with  x.bmm(y) if you do torch.bmm(x, y)\n",
    "\n",
    "# c. show that 1st elem of dim=0 of bmm(x,y) is the same as x[0].matmul(y[0])\n",
    "xy_0 = xy[0]\n",
    "x0_y0 = torch.matmul(x[0], y[0])\n",
    "print(\"Check equality: \", torch.equal(xy_0, x0_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[130.],\n",
       "        [280.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence of operations\n",
    "# a. create a tensor of size (2,2)\n",
    "x = torch.Tensor([[2, 4], \n",
    "                  [5, 10]])\n",
    "# b. create a tensor of size (1,1)\n",
    "y = torch.Tensor([[1], \n",
    "                  [1]])\n",
    "# c. use broadcasting to add 1 to every element of x using y\n",
    "# d. matrix muliply the result of c with a tensor of size (1,1)\n",
    "t = (x + y).mm(torch.Tensor([[10], [20]]))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenating tensors**\n",
    "\n",
    "We combine tensors using the cat() function, and the resulting tensor will have a shape that depends on the shape of the two input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1,2],\n",
    "                   [3,4]])\n",
    "t2 = torch.tensor([[5,6],\n",
    "                   [7,8]])\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine row-wise \n",
    "torch.cat((t1, t2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine columns wize\n",
    "torch.cat((t1, t2), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])\n",
    "\n",
    "t3 = torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 4]),\n",
       " torch.Size([4, 4]),\n",
       " torch.Size([4, 4]),\n",
       " torch.Size([4, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.stack((t1, t2, t3))\n",
    "t.shape, t1.shape, t2.shape, t3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Tensor Values** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[9.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "t = torch.Tensor([[1, 2, 3], \n",
    "                  [4, 5, 6], \n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# Every row, only the last column\n",
    "print(t[:, -1])\n",
    "\n",
    "# First 2 rows, all columns\n",
    "print(t[:2, :])\n",
    "\n",
    "# Lower right most corner\n",
    "print(t[-1:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2931])\n",
      "-0.29308679699897766\n"
     ]
    }
   ],
   "source": [
    "# If you have a one element tensor, use .item() to get the value as a Python number\n",
    "\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "tensor([[4, 3],\n",
      "        [9, 8]])\n",
      "tensor([[4, 3],\n",
      "        [4, 3]])\n"
     ]
    }
   ],
   "source": [
    "# use a range to create a vector with values in the range (0,10)\n",
    "# resize vector of size (10) to matrix of size (2,5)\n",
    "x = torch.arange(0,10).resize_((2,5))\n",
    "\n",
    "# Return max values and their position \n",
    "# k: is the number of top values to return\n",
    "# dim: the dimension to obtain the top-k values from\n",
    "topk, indices = torch.topk(x, k=2, dim=1)\n",
    "\n",
    "print(x)\n",
    "print(topk)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch Tensor To and From Numpy ndarray**\n",
    "\n",
    "You can easily create a tensors from an ndarray and vice versa. These operations are fast, since the data of both structures will share the same memory space, and so no copying is involved. This is obviously an efficient approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24169915 -0.23481165  0.39476747  1.06707743  2.17999221]\n",
      " [ 0.12580694  0.20014081  3.6688598   1.98841113  0.64940067]\n",
      " [-0.74333261  1.33172357  1.55088031  0.291102   -0.38484785]]\n",
      "tensor([[ 0.2417, -0.2348,  0.3948,  1.0671,  2.1800],\n",
      "        [ 0.1258,  0.2001,  3.6689,  1.9884,  0.6494],\n",
      "        [-0.7433,  1.3317,  1.5509,  0.2911, -0.3848]], dtype=torch.float64)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Numpy ndarray <--> PyTorch tensor\n",
    "import numpy as np\n",
    "\n",
    "# ndarray to tensor\n",
    "a = np.random.randn(3, 5)\n",
    "t = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(t)\n",
    "print(type(a))\n",
    "print(type(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GPUs\n",
    "\n",
    "PyTorch tensors have inherent GPU support. Specifying to use the GPU memory and CUDA cores for storing and performing tensor calculations is easy; the cuda package can help determine whether GPUs are available, and the package's cuda() method assigns a tensor to the GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking whether GPU is available\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# Move to GPU # \n",
    "# Note: if you did not install PyTorch with CUDA, this will throw an error\n",
    "# Note 2: if your laptop does not have an Nvidia GPU, you don't need to install the CUDA-enabled version of PyTorch\n",
    "t.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling and batching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create some dummy training data \n",
    "# a. the training and testing dataset X, Y has 200 examples \n",
    "# b. each example in X is described by 250 features (for e.g. 250 word vocab from a TFIDFVectorizer)\n",
    "# c. the target to predict has values of 0 or 1. i.e. binary classification\n",
    "X, Y = torch.randn(200, 250), torch.cat((torch.ones(100,1), torch.zeros(100,1)))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid,Y_train, Y_valid = train_test_split(X, Y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# the TensorDataset is a ready to use class to represent your data as list of tensors. \n",
    "# Note that input_features and labels must match on the length of the first dimension\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "valid_set = TensorDataset(X_valid, Y_valid)\n",
    "\n",
    "# DataLoader shuffles and batches the data and load its in parallel using multiprocessing workers\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Within the __init__ we define the layers of the module. \n",
    "\n",
    "Our three layers are an embedding layer, our RNN, and a linear layer. All layers have their parameters initialized to random values, unless explicitly specified.\n",
    "\n",
    "The embedding layer is used to transform our sparse one-hot vector (sparse as most of the elements are 0) into a dense embedding vector (dense as the dimensionality is a lot smaller and all the elements are real numbers). This embedding layer is simply a single fully connected layer. As well as reducing the dimensionality of the input to the RNN, there is the theory that words which have similar impact on the sentiment of the review are mapped close together in this dense vector spac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, batch num 0 | Loss: 0.6784\n",
      "Epoch 1/10, batch num 1 | Loss: 0.7026\n",
      "Epoch 1/10, batch num 2 | Loss: 0.6872\n",
      "Epoch 1/10, batch num 3 | Loss: 0.6870\n",
      "Epoch 1/10, batch num 4 | Loss: 0.7241\n",
      "Epoch 2/10, batch num 0 | Loss: 0.6812\n",
      "Epoch 2/10, batch num 1 | Loss: 0.6298\n",
      "Epoch 2/10, batch num 2 | Loss: 0.6870\n",
      "Epoch 2/10, batch num 3 | Loss: 0.6861\n",
      "Epoch 2/10, batch num 4 | Loss: 0.6951\n",
      "Epoch 3/10, batch num 0 | Loss: 0.6249\n",
      "Epoch 3/10, batch num 1 | Loss: 0.6239\n",
      "Epoch 3/10, batch num 2 | Loss: 0.6888\n",
      "Epoch 3/10, batch num 3 | Loss: 0.6874\n",
      "Epoch 3/10, batch num 4 | Loss: 0.6697\n",
      "Epoch 4/10, batch num 0 | Loss: 0.6501\n",
      "Epoch 4/10, batch num 1 | Loss: 0.5580\n",
      "Epoch 4/10, batch num 2 | Loss: 0.6909\n",
      "Epoch 4/10, batch num 3 | Loss: 0.6208\n",
      "Epoch 4/10, batch num 4 | Loss: 0.6857\n",
      "Epoch 5/10, batch num 0 | Loss: 0.5902\n",
      "Epoch 5/10, batch num 1 | Loss: 0.6743\n",
      "Epoch 5/10, batch num 2 | Loss: 0.6358\n",
      "Epoch 5/10, batch num 3 | Loss: 0.6297\n",
      "Epoch 5/10, batch num 4 | Loss: 0.5915\n",
      "Epoch 6/10, batch num 0 | Loss: 0.5681\n",
      "Epoch 6/10, batch num 1 | Loss: 0.6664\n",
      "Epoch 6/10, batch num 2 | Loss: 0.5729\n",
      "Epoch 6/10, batch num 3 | Loss: 0.5816\n",
      "Epoch 6/10, batch num 4 | Loss: 0.6566\n",
      "Epoch 7/10, batch num 0 | Loss: 0.6481\n",
      "Epoch 7/10, batch num 1 | Loss: 0.5835\n",
      "Epoch 7/10, batch num 2 | Loss: 0.6268\n",
      "Epoch 7/10, batch num 3 | Loss: 0.6052\n",
      "Epoch 7/10, batch num 4 | Loss: 0.5118\n",
      "Epoch 8/10, batch num 0 | Loss: 0.5542\n",
      "Epoch 8/10, batch num 1 | Loss: 0.6629\n",
      "Epoch 8/10, batch num 2 | Loss: 0.5664\n",
      "Epoch 8/10, batch num 3 | Loss: 0.5315\n",
      "Epoch 8/10, batch num 4 | Loss: 0.5844\n",
      "Epoch 9/10, batch num 0 | Loss: 0.5479\n",
      "Epoch 9/10, batch num 1 | Loss: 0.5890\n",
      "Epoch 9/10, batch num 2 | Loss: 0.5401\n",
      "Epoch 9/10, batch num 3 | Loss: 0.5486\n",
      "Epoch 9/10, batch num 4 | Loss: 0.6093\n",
      "Epoch 10/10, batch num 0 | Loss: 0.5948\n",
      "Epoch 10/10, batch num 1 | Loss: 0.5404\n",
      "Epoch 10/10, batch num 2 | Loss: 0.5570\n",
      "Epoch 10/10, batch num 3 | Loss: 0.5769\n",
      "Epoch 10/10, batch num 4 | Loss: 0.5049\n",
      "##################################################\n",
      "Validation set loss:  tensor(0.7120)\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torch import nn\n",
    "from torch import sigmoid\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, model_dimension):\n",
    "        \"\"\"\n",
    "        create an instance of the base nn.Module class\n",
    "        \"\"\"\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(model_dimension, 1)  # hidden_size in and one out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data.\n",
    "        \"\"\"\n",
    "        y_pred = sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# our model\n",
    "# NOTE: using the dummy data created above (X, Y) of sizes (200,250) and (200,1)\n",
    "linear_model = LinearModel(model_dimension = X.size(-1))\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to linear_model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "linear_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for bn, batch in enumerate(train_loader):\n",
    "        x, y = batch\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = linear_model(x)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, batch num {bn} | Loss: {loss.item():.4f}')\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('#'*50)\n",
    "# Compute loss on validation set\n",
    "linear_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = linear_model(X_valid)\n",
    "    print('Validation set loss: ', criterion(y_pred_test, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, batch num 0 | Loss: 0.8113\n",
      "Epoch 1/10, batch num 1 | Loss: 0.7186\n",
      "Epoch 1/10, batch num 2 | Loss: 0.7229\n",
      "Epoch 1/10, batch num 3 | Loss: 0.6390\n",
      "Epoch 1/10, batch num 4 | Loss: 0.7212\n",
      "Epoch 2/10, batch num 0 | Loss: 0.6905\n",
      "Epoch 2/10, batch num 1 | Loss: 0.7101\n",
      "Epoch 2/10, batch num 2 | Loss: 0.7361\n",
      "Epoch 2/10, batch num 3 | Loss: 0.6733\n",
      "Epoch 2/10, batch num 4 | Loss: 0.6912\n",
      "Epoch 3/10, batch num 0 | Loss: 0.7093\n",
      "Epoch 3/10, batch num 1 | Loss: 0.6753\n",
      "Epoch 3/10, batch num 2 | Loss: 0.6598\n",
      "Epoch 3/10, batch num 3 | Loss: 0.6487\n",
      "Epoch 3/10, batch num 4 | Loss: 0.7043\n",
      "Epoch 4/10, batch num 0 | Loss: 0.7528\n",
      "Epoch 4/10, batch num 1 | Loss: 0.6081\n",
      "Epoch 4/10, batch num 2 | Loss: 0.7039\n",
      "Epoch 4/10, batch num 3 | Loss: 0.5931\n",
      "Epoch 4/10, batch num 4 | Loss: 0.6410\n",
      "Epoch 5/10, batch num 0 | Loss: 0.6600\n",
      "Epoch 5/10, batch num 1 | Loss: 0.6425\n",
      "Epoch 5/10, batch num 2 | Loss: 0.6014\n",
      "Epoch 5/10, batch num 3 | Loss: 0.6101\n",
      "Epoch 5/10, batch num 4 | Loss: 0.6933\n",
      "Epoch 6/10, batch num 0 | Loss: 0.6998\n",
      "Epoch 6/10, batch num 1 | Loss: 0.6483\n",
      "Epoch 6/10, batch num 2 | Loss: 0.6085\n",
      "Epoch 6/10, batch num 3 | Loss: 0.5548\n",
      "Epoch 6/10, batch num 4 | Loss: 0.6089\n",
      "Epoch 7/10, batch num 0 | Loss: 0.6203\n",
      "Epoch 7/10, batch num 1 | Loss: 0.5732\n",
      "Epoch 7/10, batch num 2 | Loss: 0.5974\n",
      "Epoch 7/10, batch num 3 | Loss: 0.5730\n",
      "Epoch 7/10, batch num 4 | Loss: 0.6743\n",
      "Epoch 8/10, batch num 0 | Loss: 0.5915\n",
      "Epoch 8/10, batch num 1 | Loss: 0.6279\n",
      "Epoch 8/10, batch num 2 | Loss: 0.5800\n",
      "Epoch 8/10, batch num 3 | Loss: 0.5749\n",
      "Epoch 8/10, batch num 4 | Loss: 0.5844\n",
      "Epoch 9/10, batch num 0 | Loss: 0.5793\n",
      "Epoch 9/10, batch num 1 | Loss: 0.5901\n",
      "Epoch 9/10, batch num 2 | Loss: 0.5516\n",
      "Epoch 9/10, batch num 3 | Loss: 0.6067\n",
      "Epoch 9/10, batch num 4 | Loss: 0.5583\n",
      "Epoch 10/10, batch num 0 | Loss: 0.6118\n",
      "Epoch 10/10, batch num 1 | Loss: 0.5966\n",
      "Epoch 10/10, batch num 2 | Loss: 0.5412\n",
      "Epoch 10/10, batch num 3 | Loss: 0.5488\n",
      "Epoch 10/10, batch num 4 | Loss: 0.5213\n",
      "##################################################\n",
      "Validation set loss:  tensor(0.6676)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import sigmoid\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, model_dimension):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate nn.Linear module\n",
    "        \"\"\"\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.linear = nn.Linear(model_dimension, 1)  # One in and one out\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data.\n",
    "        \"\"\"\n",
    "        y_pred = sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "# our model\n",
    "mlp_model = MLPModel(model_dimension = X.size(-1))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "mlp_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for bn, batch in enumerate(train_loader):\n",
    "        x, y = batch\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = mlp_model(x)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, batch num {bn} | Loss: {loss.item():.4f}')\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('#'*50)\n",
    "# Compute loss on validation set\n",
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = mlp_model(X_valid)\n",
    "    print('Validation set loss: ', criterion(y_pred_test, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embed): Embedding(3000, 100)\n",
      "  (rnn): GRU(100, 75, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (decision): Linear(in_features=75, out_features=2, bias=True)\n",
      ")\n",
      "Epoch 1/10, batch num 0 | Loss: 0.7213\n",
      "Epoch 1/10, batch num 1 | Loss: 0.6757\n",
      "Epoch 1/10, batch num 2 | Loss: 0.6960\n",
      "Epoch 1/10, batch num 3 | Loss: 0.7255\n",
      "Epoch 1/10, batch num 4 | Loss: 0.7369\n",
      "Epoch 2/10, batch num 0 | Loss: 0.6966\n",
      "Epoch 2/10, batch num 1 | Loss: 0.7453\n",
      "Epoch 2/10, batch num 2 | Loss: 0.6703\n",
      "Epoch 2/10, batch num 3 | Loss: 0.6641\n",
      "Epoch 2/10, batch num 4 | Loss: 0.6971\n",
      "Epoch 3/10, batch num 0 | Loss: 0.6648\n",
      "Epoch 3/10, batch num 1 | Loss: 0.6935\n",
      "Epoch 3/10, batch num 2 | Loss: 0.7063\n",
      "Epoch 3/10, batch num 3 | Loss: 0.6829\n",
      "Epoch 3/10, batch num 4 | Loss: 0.7083\n",
      "Epoch 4/10, batch num 0 | Loss: 0.6844\n",
      "Epoch 4/10, batch num 1 | Loss: 0.6834\n",
      "Epoch 4/10, batch num 2 | Loss: 0.7069\n",
      "Epoch 4/10, batch num 3 | Loss: 0.6667\n",
      "Epoch 4/10, batch num 4 | Loss: 0.6949\n",
      "Epoch 5/10, batch num 0 | Loss: 0.6902\n",
      "Epoch 5/10, batch num 1 | Loss: 0.7186\n",
      "Epoch 5/10, batch num 2 | Loss: 0.6958\n",
      "Epoch 5/10, batch num 3 | Loss: 0.6712\n",
      "Epoch 5/10, batch num 4 | Loss: 0.7013\n",
      "Epoch 6/10, batch num 0 | Loss: 0.6911\n",
      "Epoch 6/10, batch num 1 | Loss: 0.7045\n",
      "Epoch 6/10, batch num 2 | Loss: 0.6940\n",
      "Epoch 6/10, batch num 3 | Loss: 0.6620\n",
      "Epoch 6/10, batch num 4 | Loss: 0.7474\n",
      "Epoch 7/10, batch num 0 | Loss: 0.7126\n",
      "Epoch 7/10, batch num 1 | Loss: 0.6975\n",
      "Epoch 7/10, batch num 2 | Loss: 0.6864\n",
      "Epoch 7/10, batch num 3 | Loss: 0.7025\n",
      "Epoch 7/10, batch num 4 | Loss: 0.6903\n",
      "Epoch 8/10, batch num 0 | Loss: 0.6845\n",
      "Epoch 8/10, batch num 1 | Loss: 0.6519\n",
      "Epoch 8/10, batch num 2 | Loss: 0.6810\n",
      "Epoch 8/10, batch num 3 | Loss: 0.6631\n",
      "Epoch 8/10, batch num 4 | Loss: 0.7167\n",
      "Epoch 9/10, batch num 0 | Loss: 0.6506\n",
      "Epoch 9/10, batch num 1 | Loss: 0.6672\n",
      "Epoch 9/10, batch num 2 | Loss: 0.6756\n",
      "Epoch 9/10, batch num 3 | Loss: 0.7035\n",
      "Epoch 9/10, batch num 4 | Loss: 0.6929\n",
      "Epoch 10/10, batch num 0 | Loss: 0.6942\n",
      "Epoch 10/10, batch num 1 | Loss: 0.6760\n",
      "Epoch 10/10, batch num 2 | Loss: 0.6851\n",
      "Epoch 10/10, batch num 3 | Loss: 0.6838\n",
      "Epoch 10/10, batch num 4 | Loss: 0.6716\n",
      "##################################################\n",
      "Validation set loss:  tensor(0.6887)\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Here we define the network layers\n",
    "        \n",
    "        # An embedding layer projecting vectors of size vocab_size into embeddings of size embed_size\n",
    "        # Assigns to each word in the vocabulary an embedding vector of size embed_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # A recurrent (GRU) layer to process each input token (represented by its embedding)\n",
    "        # The GRU network takes as input the embedding (of size embed_size) of the current word \n",
    "        # and the previous hidden state (of size hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        # Drop out layer for regularisation\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully connected layer mapping \n",
    "        # the last layer maps a hidden state to a vector of size the number of classes\n",
    "        self.decision = nn.Linear(hidden_size, num_labels)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        # Here we say how the layers are connected \n",
    "       \n",
    "        # for each token in the input, retrieve the corresponding embeddings \n",
    "        # x = [batch size, max sent length]\n",
    "        embed = self.embed(x)\n",
    "        \n",
    "        # Run the RNN on the input embeddings\n",
    "        # embed = [batch size, sent len, emb dim]\n",
    "        # output is the sequence of hidden states produced by the RNN\n",
    "        # hidden is the last hidden state produced\n",
    "        output, hidden = self.rnn(embed)\n",
    "        \n",
    "        # output = [sent len, batch size, hidden size]\n",
    "        # hidden = [num_layers * num_directions, batch, hidden_size]\n",
    "        \n",
    "        # Apply dropout (for regularisation)\n",
    "        drop = self.dropout(hidden)\n",
    "        \n",
    "        # Apply the fully connected layer to the output of the dropout\n",
    "        # drop = [num_layers * num_directions, batch_size, hidden_size]\n",
    "        # Expected output shape: (batch_size, num_labels)\n",
    "        return self.decision(drop.squeeze()) # or:  self.decision(drop.view(x.size(0), -1))\n",
    "\n",
    "# NOTE: we will be using a different set of dummy training data from above (X,Y)\n",
    "# NOTE: X here is of size (200, 250) which corresponds to (batch_size, sequence length)\n",
    "# NOTE: create X as a randint tensor of size (200,250) with the highest value of 3000 (think of this as vocab size)\n",
    "X, Y = torch.randint(3000, (200, 250), dtype=torch.long), torch.cat((torch.ones(100, dtype=torch.long), \n",
    "                                                                     torch.zeros(100, dtype=torch.long)))\n",
    "X_train, X_valid,Y_train, Y_valid = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
    "train_set = TensorDataset(X_train, Y_train)\n",
    "valid_set = TensorDataset(X_valid, Y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32)\n",
    "\n",
    "\n",
    "# 1. instantiate the RNN with the required parameter values\n",
    "# NOTE: hidden_size and embed_size are the dimensions for the internal layers of the network\n",
    "rnn_model = RNN(vocab_size = len(X.unique()), embed_size= 100, hidden_size = 75, num_labels = len(Y.unique()))\n",
    "# 2. check for cuda availablilty. set gpu/cpu device usage accordingly\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# 3. set the model to the device to use for computation \n",
    "rnn_model.to(device)\n",
    "print(rnn_model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "rnn_model.train()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for bn, batch in enumerate(train_loader):\n",
    "        x, y = batch\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = rnn_model(x)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, batch num {bn} | Loss: {loss.item():.4f}')\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('#'*50)\n",
    "# Compute loss on validation set\n",
    "rnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = rnn_model(X_valid)\n",
    "    print('Validation set loss: ', criterion(y_pred_test, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer\n",
    "\n",
    "* The nn.Embedding module holds a Tensor of dimension (vocab_size, embedding_size), i.e. of the size of the vocabulary x the dimension of each vector embedding, and a method for retrieving the embedding of a word. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8339, -0.8401, -0.4141,  0.7291, -0.3189, -0.7835,  1.1149,  1.6854,\n",
       "          0.8369, -0.5857, -0.8683, -1.6540,  1.0870, -1.0315, -0.4118,  1.0056,\n",
       "          0.3092, -1.1671,  0.2132,  0.6444, -1.4036,  1.1835,  2.1626, -1.8322,\n",
       "         -0.6601,  0.5682, -0.7845, -0.7873, -1.8262, -0.5982, -1.9202, -0.2246,\n",
       "         -1.1471,  0.4236, -0.2028,  1.4375,  1.2629,  0.8292, -1.4450, -0.3609,\n",
       "          1.6184,  0.2269, -0.0455, -2.0148, -0.6915, -1.1114,  1.2323, -0.0207,\n",
       "         -0.5399, -0.4170, -0.4824, -0.4848,  0.4060,  1.1731, -0.6320, -1.4604,\n",
       "          0.5150, -0.5422, -1.4209, -0.3815, -0.0864, -1.4695,  0.3017,  0.8218,\n",
       "         -0.0975,  0.8161, -0.1343,  0.2470,  0.9689,  0.4680,  1.6157,  1.0490,\n",
       "         -0.3120,  0.7378, -0.9465, -0.7687,  0.8759, -1.0310, -0.8165, -1.1310,\n",
       "          0.6545, -0.8943,  0.4720, -0.6477, -0.8004, -0.0692,  0.1378,  0.7362,\n",
       "          0.6140,  1.5090, -0.7292, -2.0434, -0.2622, -0.6968,  1.3669, -1.1981,\n",
       "          0.7943,  1.6262, -0.3108,  1.1458,  1.4804, -0.2836, -0.4130, -0.4645,\n",
       "         -0.3161,  0.3990,  0.0048, -0.9098, -1.0426, -0.1452, -0.4645,  0.6342,\n",
       "         -0.2915,  1.0120,  0.8109,  0.6790,  0.0800,  1.1314, -1.3636,  0.1436,\n",
       "         -0.6072, -0.4201, -0.8670, -0.5404,  0.1881, -1.3230, -0.5973, -1.1090]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an embedding layer\n",
    "# Parameters: (vocab_size, embedding_size)\n",
    "embedding = nn.Embedding(1000,128)\n",
    "# Print out the embedding of the token represented by index 3\n",
    "embedding(torch.LongTensor([3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Layer\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* in_features – size of each input sample\n",
    "* out_features – size of each output sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6191],\n",
       "        [-0.3373],\n",
       "        [-0.1708]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#x contains three inputs (i.e. the batch size is 3),\n",
    "x = torch.tensor([[1.0, -1.0],\n",
    "                  [0.0,  1.0],\n",
    "                  [0.0,  0.0]])\n",
    "\n",
    "in_features = x.shape[1]  # = 2\n",
    "out_features = 1\n",
    "\n",
    "# input x of shape (batch_size, in_features)\n",
    "# output of shape (batchsize, out_features)\n",
    "m = nn.Linear(in_features, out_features)\n",
    "\n",
    "# output\n",
    "y = m(x)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
