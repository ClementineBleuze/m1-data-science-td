{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise \"Lecture 11: Lexical Semantics\"\n",
    "\n",
    "\n",
    "In this set of exercises, we will convert words to vectors representing their distributional properties. \n",
    "\n",
    "In the first part, you will use Gensim and sklearn predefined methods to build an SVD word context matrix from the Wikipedia corpus used in the preceding two lectures and  use cosine to compare the similarity between the vectors representing   words. \n",
    "\n",
    "In the second part, you will build a word cooccurrences matrix from the Wikipedia corpus. \n",
    "\n",
    "The exercises cover the following points:\n",
    "\n",
    "\n",
    "* Creating word coocurrence matrices\n",
    "* Applying SVD decomposition\n",
    "* Finding neighbours\n",
    "* Converting a corpus to a list of integers where each integer represent a token (this is needed for efficient computation)\n",
    "* Computing a word frequency distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store a set of files into a Pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Store all files in 'data/wkp/' into a pandas dataframe with column Text where each row contains the content of one file\n",
    "\n",
    "* use os.scandir to list the files in the directory   \n",
    "    **11_CS_lexical_semantics-1** \n",
    "* read each file into a list of strings (one string per file)  \n",
    "    **11_CS_python-2**\n",
    "* store the list of strings into a pandas dataframe with header 'Text'   \n",
    "    **08, pandas_cheat_sheet**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al MacKenzie is a fictional character appearin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannonball (Samuel Zachary Guthrie) is a ficti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A list of the Famous Studios theatrical cartoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Pierce is a fictional supervillain appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elongated Man (Randolph \"Ralph\" Dibny) is a fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Al MacKenzie is a fictional character appearin...\n",
       "1  Cannonball (Samuel Zachary Guthrie) is a ficti...\n",
       "2  A list of the Famous Studios theatrical cartoo...\n",
       "3  Donald Pierce is a fictional supervillain appe...\n",
       "4  Elongated Man (Randolph \"Ralph\" Dibny) is a fi..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "from os import scandir\n",
    "\n",
    "DIR = \"Comics_characters/\"\n",
    "\n",
    "# Load the data from the directory DIR using os.scandir\n",
    "data = []\n",
    "for entry in scandir(DIR):\n",
    "    if entry.is_file() and entry.name.endswith(\".txt\"):\n",
    "        with open(entry.path, \"r\") as f:\n",
    "            data.append(f.read())\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating a word cooccurence matrix using vectorizers\n",
    "\n",
    "\n",
    "* Use sklearn vectorizer methods (CountVectorizer, TfidfVectorizer) to convert the corpus (a list of documents) to a _**document/token matrix**_\n",
    "* Use algebra to create the token/token matrix.  To create a _**token co-occurence matrix**_ , we simply multiply the transpose of the documents/tokens matrix by the documents/token matrix\n",
    "    * shape of X: (#doc, #tokens)   \n",
    "    * shape of X transpose: (#tokens, #doc)   \n",
    "    * shape of X transpose * X : (#tokens, #doc) * (#doc, #tokens) = (#tokens, #tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** \n",
    "* Convert the Text column of the dataframe created in Exercise 1 into a list of strings   \n",
    "   **Pandas CS-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list(df[\"text\"])\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3:** Creating a document / token matrix\n",
    "\n",
    "* Use sklearn [sklearn.feature_extraction.text.CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) method which transforms a list of documents (strings) into a a document/token matrix where each cell indicates the frequency of a token in a document\n",
    "* Use the stop_words option to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 2]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "(10, 3729)\n"
     ]
    }
   ],
   "source": [
    "print(X.todense())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4:** Print out the word distribution i.e.,  the tokens contained in the document/token matrix and their frequency (use the vocabulary_ attribute of CountVectorizer module, cf. CS)\n",
    "\n",
    "Your output should look like this:\n",
    "\n",
    "{'donald': 1086, 'pierce': 2502, 'fictional': 1361, 'supervillain': 3261, 'appearing': 280, 'american': 242, 'comic': 720, 'books': 487, 'published': 2650, 'marvel': 2153, 'comics': 722, 'character': 631, 'depicted': 980, 'cyborg': 895, 'commonly': 731, 'enemy': 1205, 'men': 2193, 'portrayed': 2540, 'boyd': 501, 'holbrook': 1659, '2017': 64, 'film': 1371, 'logan': 2052, 'publication': 2649, 'history': 1655, 'appeared': 279, 'uncanny': 3497, '132': 14, 'april': 287, '1980': 32, 'created': 849, 'chris': 659, 'claremont': 677, 'john': 1875, 'byrne': 549, 'appearance': 277, 'modeled': 2247, 'sutherland': 3287, 'comes': 718, 'benjamin': 432, 'franklin': 1435, 'hawkeye': 1602, '1970': 28, 'biography': 448, 'born': 492, 'philadelphia': 2487, 'pennsylvania': 2466, 'appears': 281, 'high': 1647, 'ranking': 2687, 'member': 2187, 'inner': 1797, 'circle': 665, 'hellfire': 1625, 'club': 693, 'holds': 1663, 'position': 2543, 'white': 3656, 'bishop': 451, 'fact': 1318, 'genocidal': 1488, 'mutant': 2289, 'hater': 1595, 'joined': 1877, 'order': 2405, 'kill': 1915, 'members': 2188, 'mutants': 2290, 'addition': 160, 'hating': 1597, 'bigoted': 443, 'certain': 621, 'nationalities': 2312, 'harbors': 1584, 'sense': 2990, 'self': 2986, 'loathing': 2044, 'status': 3177, 'referring': 2739, 'half': 1571, 'man': 2124, 'ceo': 617, 'principal': 2595, 'shareholder': 3029, 'consolidated': 776, 'mining': 2225, 'operates': 2392, 'laboratory': 1946, 'complex': 742, 'cameron': 567, 'kentucky': 1906, 'mercenaries': 2198, 'kidnap': ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'al': 205,\n",
       " 'mackenzie': 2095,\n",
       " 'fictional': 1362,\n",
       " 'character': 631,\n",
       " 'appearing': 280,\n",
       " 'american': 242,\n",
       " 'comic': 720,\n",
       " 'books': 487,\n",
       " 'published': 2652,\n",
       " 'marvel': 2155,\n",
       " 'comics': 722,\n",
       " 'alphonso': 228,\n",
       " 'mack': 2094,\n",
       " 'appeared': 279,\n",
       " 'cinematic': 664,\n",
       " 'universe': 3526,\n",
       " 'tv': 3476,\n",
       " 'series': 3004,\n",
       " 'agents': 193,\n",
       " 'portrayed': 2542,\n",
       " 'henry': 1636,\n",
       " 'simmons': 3064,\n",
       " 'eventually': 1260,\n",
       " 'new': 2333,\n",
       " 'director': 1045,\n",
       " 'publication': 2651,\n",
       " 'history': 1656,\n",
       " 'nick': 2338,\n",
       " 'fury': 1457,\n",
       " 'vs': 3619,\n",
       " 'aug': 363,\n",
       " '1988': 39,\n",
       " 'created': 849,\n",
       " 'bob': 474,\n",
       " 'harras': 1590,\n",
       " 'paul': 2461,\n",
       " 'neary': 2320,\n",
       " 'subsequently': 3233,\n",
       " 'appears': 281,\n",
       " 'agent': 192,\n",
       " 'sept': 3000,\n",
       " '1989': 40,\n",
       " 'jan': 1857,\n",
       " '1990': 41,\n",
       " 'entry': 1233,\n",
       " 'issue': 1850,\n",
       " 'reference': 2738,\n",
       " 'official': 2379,\n",
       " 'handbook': 1576,\n",
       " 'update': 3542,\n",
       " '89': 115,\n",
       " 'biography': 448,\n",
       " 'born': 492,\n",
       " 'austin': 366,\n",
       " 'texas': 3358,\n",
       " 'liaison': 2014,\n",
       " 'romantically': 2893,\n",
       " 'involved': 1840,\n",
       " 'contessa': 790,\n",
       " 'valentina': 3563,\n",
       " 'allegra': 215,\n",
       " 'di': 1017,\n",
       " 'fontaine': 1412,\n",
       " 'led': 1993,\n",
       " 'estrangement': 1251,\n",
       " 'returned': 2841,\n",
       " 'cia': 662,\n",
       " 'later': 1969,\n",
       " 'joined': 1878,\n",
       " 'organization': 2411,\n",
       " 'time': 3390,\n",
       " 'spent': 3142,\n",
       " 'considerable': 774,\n",
       " 'senior': 2991,\n",
       " 'officer': 2377,\n",
       " 'unknown': 3529,\n",
       " 'circumstances': 669,\n",
       " 'resigned': 2810,\n",
       " 'wrote': 3706,\n",
       " 'tell': 3341,\n",
       " 'book': 486,\n",
       " 'entitled': 1230,\n",
       " 'unshielded': 3539,\n",
       " 'unauthorized': 3498,\n",
       " 'insider': 1803,\n",
       " 'look': 2060,\n",
       " 'world': 3695,\n",
       " 'powerful': 2561,\n",
       " 'global': 1514,\n",
       " 'spy': 3156,\n",
       " 'network': 2331,\n",
       " 'purportedly': 2663,\n",
       " 'explained': 1289,\n",
       " 'point': 2533,\n",
       " 'view': 3594,\n",
       " 'acted': 145,\n",
       " 'unofficial': 3536,\n",
       " 'source': 3124,\n",
       " 'ben': 427,\n",
       " 'urich': 3552,\n",
       " 'prodding': 2610,\n",
       " 'jessica': 1866,\n",
       " 'jones': 1883,\n",
       " 'attempt': 351,\n",
       " 'expose': 1296,\n",
       " 'mission': 2240,\n",
       " 'latveria': 1972,\n",
       " 'media': 2184,\n",
       " 'goes': 1518,\n",
       " 'nickname': 2339,\n",
       " 'african': 187,\n",
       " 'mechanic': 2181,\n",
       " 'engineer': 1211,\n",
       " 'recruited': 2727,\n",
       " 'newly': 2336,\n",
       " 'rebuilt': 2717,\n",
       " 'phil': 2488,\n",
       " 'coulson': 826,\n",
       " 'events': 1259,\n",
       " 'film': 1372,\n",
       " 'captain': 581,\n",
       " 'america': 241,\n",
       " 'winter': 3672,\n",
       " 'soldier': 3108,\n",
       " 'old': 2381,\n",
       " 'friends': 1445,\n",
       " 'barbara': 395,\n",
       " 'bobbi': 475,\n",
       " 'morse': 2269,\n",
       " 'develops': 1009,\n",
       " 'close': 691,\n",
       " 'friendship': 1446,\n",
       " 'leo': 2003,\n",
       " 'fitz': 1387,\n",
       " 'romantic': 2892,\n",
       " 'relationship': 2769,\n",
       " 'elena': 1166,\n",
       " 'yo': 3715,\n",
       " 'rodriguez': 2888,\n",
       " 'ill': 1709,\n",
       " 'health': 1612,\n",
       " 'subsequent': 3232,\n",
       " 'death': 940,\n",
       " 'final': 1375,\n",
       " 'episode': 1235,\n",
       " 'fighting': 1366,\n",
       " 'continues': 794,\n",
       " 'lead': 1977,\n",
       " 'reprises': 2801,\n",
       " 'role': 2890,\n",
       " 'web': 3648,\n",
       " 'titled': 3399,\n",
       " 'slingshot': 3091,\n",
       " 'references': 2739,\n",
       " 'external': 1306,\n",
       " 'links': 2036,\n",
       " 'wiki': 3666,\n",
       " 'cannonball': 577,\n",
       " 'samuel': 2927,\n",
       " 'zachary': 3722,\n",
       " 'guthrie': 1566,\n",
       " 'superhero': 3255,\n",
       " 'commonly': 731,\n",
       " 'association': 338,\n",
       " 'men': 2195,\n",
       " 'writer': 3703,\n",
       " 'chris': 659,\n",
       " 'claremont': 677,\n",
       " 'artist': 313,\n",
       " 'mcleod': 2175,\n",
       " 'mutants': 2292,\n",
       " '1982': 33,\n",
       " 'mutant': 2291,\n",
       " 'uses': 3556,\n",
       " 'ability': 120,\n",
       " 'fly': 1406,\n",
       " 'jet': 1867,\n",
       " 'speeds': 3139,\n",
       " 'encased': 1194,\n",
       " 'impenetrable': 1719,\n",
       " 'force': 1415,\n",
       " 'field': 1363,\n",
       " 'founding': 1429,\n",
       " 'member': 2189,\n",
       " 'junior': 1895,\n",
       " 'team': 3319,\n",
       " 'served': 3008,\n",
       " 'second': 2971,\n",
       " 'command': 724,\n",
       " 'leader': 1978,\n",
       " 'secondary': 2972,\n",
       " 'graduate': 1528,\n",
       " 'eldest': 1159,\n",
       " 'large': 1965,\n",
       " 'kentucky': 1907,\n",
       " 'coal': 695,\n",
       " 'mining': 2227,\n",
       " 'family': 1333,\n",
       " 'siblings': 3054,\n",
       " 'husk': 1695,\n",
       " 'aero': 179,\n",
       " 'icarus': 1698,\n",
       " 'jeb': 1863,\n",
       " 'related': 2768,\n",
       " 'teams': 3323,\n",
       " 'charlie': 638,\n",
       " 'heaton': 1618,\n",
       " 'sam': 2923,\n",
       " '2020': 67,\n",
       " 'graphic': 1534,\n",
       " 'novel': 2359,\n",
       " 'september': 3001,\n",
       " 'titular': 3400,\n",
       " 'super': 3253,\n",
       " 'group': 1551,\n",
       " 'commented': 729,\n",
       " 'liked': 2021,\n",
       " 'best': 435,\n",
       " 'tried': 3453,\n",
       " 'distinct': 1072,\n",
       " 'body': 478,\n",
       " 'types': 3483,\n",
       " 'characteristics': 632,\n",
       " 'big': 441,\n",
       " 'ears': 1138,\n",
       " 'lanky': 1962,\n",
       " 'frame': 1431,\n",
       " 'just': 1897,\n",
       " 'fun': 1453,\n",
       " 'draw': 1107,\n",
       " 'guest': 1560,\n",
       " 'appearance': 277,\n",
       " 'uncanny': 3501,\n",
       " '167': 18,\n",
       " 'regularly': 2761,\n",
       " 'title': 3398,\n",
       " 'hundredth': 1686,\n",
       " '1983': 34,\n",
       " '1991': 43,\n",
       " 'continued': 793,\n",
       " 'appear': 276,\n",
       " 'replacement': 2794,\n",
       " '44': 91,\n",
       " '1995': 44,\n",
       " 'leaves': 1991,\n",
       " 'join': 1877,\n",
       " '48': 99,\n",
       " '323': 84,\n",
       " '355': 85,\n",
       " '1998': 45,\n",
       " 'rejoins': 2767,\n",
       " 'extended': 1300,\n",
       " 'road': 2875,\n",
       " 'trip': 3458,\n",
       " '86': 114,\n",
       " 'stays': 3182,\n",
       " '117': 6,\n",
       " '2001': 48,\n",
       " 'changes': 627,\n",
       " 'drastically': 1106,\n",
       " 'taken': 3303,\n",
       " 'known': 1938,\n",
       " 'statix': 3177,\n",
       " 'corporation': 812,\n",
       " '128': 9,\n",
       " '130': 12,\n",
       " '131': 13,\n",
       " '140': 15,\n",
       " '2002': 49,\n",
       " '2003': 50,\n",
       " 'splinter': 3149,\n",
       " 'storm': 3200,\n",
       " 'treme': 3446,\n",
       " '24': 77,\n",
       " '46': 94,\n",
       " '2004': 51,\n",
       " 'cancellation': 574,\n",
       " 'mid': 2219,\n",
       " 'late': 1967,\n",
       " '2000s': 47,\n",
       " 'including': 1741,\n",
       " '444': 92,\n",
       " '447': 93,\n",
       " '466': 97,\n",
       " '474': 98,\n",
       " '2006': 53,\n",
       " '188': 20,\n",
       " '204': 70,\n",
       " '2007': 54,\n",
       " 'young': 3718,\n",
       " '2008': 55,\n",
       " 'secret': 2973,\n",
       " 'invasion': 1831,\n",
       " '2009': 56,\n",
       " 'sunspot': 3252,\n",
       " 'astonishing': 342,\n",
       " 'tales': 3307,\n",
       " 'relaunched': 2773,\n",
       " 'volume': 3617,\n",
       " 'penned': 2467,\n",
       " 'zeb': 3727,\n",
       " 'wells': 3655,\n",
       " 'incarnation': 1737,\n",
       " 'strike': 3217,\n",
       " 'defined': 969,\n",
       " 'roster': 2897,\n",
       " 'mirage': 2233,\n",
       " 'karma': 1902,\n",
       " 'magma': 2106,\n",
       " 'magik': 2105,\n",
       " 'cypher': 900,\n",
       " 'warlock': 3625,\n",
       " 'regular': 2760,\n",
       " '25': 78,\n",
       " '2011': 58,\n",
       " 'major': 2119,\n",
       " 'fixture': 1389,\n",
       " 'coming': 723,\n",
       " 'event': 1258,\n",
       " '523â': 102,\n",
       " '524': 103,\n",
       " '36': 86,\n",
       " 'legacy': 1996,\n",
       " '234': 74,\n",
       " '235': 75,\n",
       " '2010': 57,\n",
       " 'featured': 1351,\n",
       " 'hellbound': 1625,\n",
       " 'miniseries': 2229,\n",
       " 'leading': 1981,\n",
       " 'pixie': 2509,\n",
       " 'gambit': 1467,\n",
       " 'anole': 258,\n",
       " 'dazzler': 928,\n",
       " 'trance': 3427,\n",
       " 'northstar': 2353,\n",
       " 'limbo': 2026,\n",
       " 'rescue': 2804,\n",
       " 'age': 190,\n",
       " 'suffered': 3241,\n",
       " 'mental': 2196,\n",
       " 'trauma': 3439,\n",
       " 'bastion': 403,\n",
       " 'constant': 777,\n",
       " 'siege': 3057,\n",
       " 'causing': 609,\n",
       " 'leave': 1990,\n",
       " 'regenesis': 2755,\n",
       " 'vol': 3614,\n",
       " 'base': 398,\n",
       " 'utopia': 3559,\n",
       " 'wolverine': 3684,\n",
       " 'faction': 1320,\n",
       " 'jean': 1862,\n",
       " 'grey': 1545,\n",
       " 'school': 2954,\n",
       " 'higher': 1649,\n",
       " 'learning': 1988,\n",
       " 'york': 3716,\n",
       " 'joining': 1879,\n",
       " 'rogue': 2889,\n",
       " '260': 80,\n",
       " '267': 81,\n",
       " '2012': 59,\n",
       " 'asked': 322,\n",
       " 'avengers': 374,\n",
       " 'bridging': 520,\n",
       " 'gap': 1473,\n",
       " 'humans': 1684,\n",
       " 'aftermath': 189,\n",
       " '23': 73,\n",
       " '2013': 60,\n",
       " '38': 87,\n",
       " '2015': 62,\n",
       " '18': 19,\n",
       " '2014': 61,\n",
       " '12': 8,\n",
       " '2017': 64,\n",
       " '675': 108,\n",
       " '690': 109,\n",
       " '2018': 65,\n",
       " 'surrender': 3275,\n",
       " 'rejoined': 2766,\n",
       " 'remains': 2781,\n",
       " 'origin': 2414,\n",
       " 'cumberland': 880,\n",
       " 'boy': 500,\n",
       " 'attempted': 352,\n",
       " 'help': 1631,\n",
       " 'working': 3693,\n",
       " 'father': 1344,\n",
       " 'worked': 3690,\n",
       " 'died': 1026,\n",
       " 'day': 926,\n",
       " 'finds': 1378,\n",
       " 'trapped': 3437,\n",
       " 'collapsing': 704,\n",
       " 'shaft': 3023,\n",
       " 'trying': 3469,\n",
       " 'fellow': 1361,\n",
       " 'worker': 3692,\n",
       " 'mr': 2277,\n",
       " 'lewis': 2012,\n",
       " 'unconsciously': 3506,\n",
       " 'manifests': 2136,\n",
       " 'saves': 2941,\n",
       " 'soon': 3115,\n",
       " 'hired': 1653,\n",
       " 'donald': 1087,\n",
       " 'pierce': 2504,\n",
       " 'hellfire': 1626,\n",
       " 'club': 693,\n",
       " 'attack': 346,\n",
       " 'orders': 2408,\n",
       " 'kill': 1916,\n",
       " 'defeated': 966,\n",
       " 'rebels': 2712,\n",
       " 'charles': 637,\n",
       " 'xavier': 3707,\n",
       " 'asks': 324,\n",
       " 'does': 1081,\n",
       " 'alias': 211,\n",
       " 'teammate': 3321,\n",
       " 'brotherly': 535,\n",
       " 'affection': 183,\n",
       " 'rahne': 2681,\n",
       " 'unaware': 3499,\n",
       " 'feelings': 1356,\n",
       " 'danielle': 911,\n",
       " 'moonstar': 2265,\n",
       " 'act': 144,\n",
       " 'leaders': 1979,\n",
       " 'supervises': 3264,\n",
       " 'teammates': 3322,\n",
       " 'helps': 1634,\n",
       " 'adventures': 174,\n",
       " 'space': 3127,\n",
       " 'ancient': 246,\n",
       " 'scotland': 2958,\n",
       " 'galaxies': 1465,\n",
       " 'meets': 2187,\n",
       " 'rock': 2885,\n",
       " 'musician': 2290,\n",
       " 'lila': 2023,\n",
       " 'cheney': 647,\n",
       " 'begins': 419,\n",
       " 'beyonder': 439,\n",
       " 'encounters': 1199,\n",
       " 'kills': 1921,\n",
       " 'resurrects': 2834,\n",
       " 'deeply': 964,\n",
       " 'shaken': 3024,\n",
       " 'villainous': 3596,\n",
       " 'emma': 1182,\n",
       " 'frost': 1448,\n",
       " 'massachusetts': 2161,\n",
       " 'academy': 128,\n",
       " 'hellions': 1628,\n",
       " 'come': 716,\n",
       " 'senses': 2994,\n",
       " 'wolfsbane': 3683,\n",
       " 'rictor': 2859,\n",
       " 'tabitha': 3302,\n",
       " 'kidnapped': 1913,\n",
       " 'grounds': 1550,\n",
       " 'mansion': 2141,\n",
       " 'genoshan': 1491,\n",
       " 'forces': 1418,\n",
       " 'control': 800,\n",
       " 'cameron': 567,\n",
       " 'hodge': 1659,\n",
       " 'murdered': 2282,\n",
       " 'powers': 2562,\n",
       " 'joins': 1880,\n",
       " 'genosha': 1490,\n",
       " 'government': 1526,\n",
       " 'toppled': 3407,\n",
       " 'victims': 3588,\n",
       " 'regime': 2756,\n",
       " 'supervision': 3265,\n",
       " 'cable': 551,\n",
       " 'hard': 1586,\n",
       " 'edged': 1145,\n",
       " 'appointed': 283,\n",
       " 'impaled': 1717,\n",
       " 'killed': 1917,\n",
       " 'clash': 679,\n",
       " 'brotherhood': 534,\n",
       " 'heals': 1611,\n",
       " 'minutes': 2232,\n",
       " 'reveals': 2849,\n",
       " 'dystopian': 1134,\n",
       " 'future': 1458,\n",
       " 'ruled': 2903,\n",
       " 'apocalypse': 271,\n",
       " 'explains': 1291,\n",
       " 'believes': 424,\n",
       " 'particularly': 2455,\n",
       " 'rare': 2692,\n",
       " 'type': 3482,\n",
       " 'virtually': 3603,\n",
       " 'immortal': 1714,\n",
       " 'externals': 1307,\n",
       " 'saul': 2938,\n",
       " 'gideon': 1502,\n",
       " 'believe': 421,\n",
       " 'sister': 3070,\n",
       " 'paige': 2440,\n",
       " 'revealed': 2847,\n",
       " 'easy': 1142,\n",
       " 'considered': 775,\n",
       " 'line': 2034,\n",
       " 'outright': 2424,\n",
       " 'criminals': 859,\n",
       " 'devolves': 1012,\n",
       " 'fight': 1365,\n",
       " 'rivalries': 2873,\n",
       " 'aside': 320,\n",
       " 'instrumental': 1809,\n",
       " 'helping': 1633,\n",
       " 'forge': 1422,\n",
       " 'defeat': 965,\n",
       " 'phalanx': 2484,\n",
       " 'initially': 1787,\n",
       " 'excited': 1271,\n",
       " 'doubt': 1096,\n",
       " 'abilities': 119,\n",
       " 'faces': 1317,\n",
       " 'battles': 407,\n",
       " 'shi': 3035,\n",
       " 'ar': 290,\n",
       " 'gladiator': 1513,\n",
       " 'standstill': 3167,\n",
       " 'strained': 3205,\n",
       " 'turns': 3475,\n",
       " 'friend': 1443,\n",
       " 'support': 3268,\n",
       " 'ailing': 202,\n",
       " 'mother': 2270,\n",
       " 'infiltrates': 1771,\n",
       " 'presidential': 2580,\n",
       " 'campaign': 569,\n",
       " 'anti': 264,\n",
       " 'candidate': 575,\n",
       " 'graydon': 1538,\n",
       " 'creed': 854,\n",
       " 'using': 3557,\n",
       " 'samson': 2926,\n",
       " 'guthry': 1567,\n",
       " 'despite': 990,\n",
       " 'transparent': 3435,\n",
       " 'able': 121,\n",
       " 'remain': 2778,\n",
       " 'undetected': 3516,\n",
       " 'assassinated': 326,\n",
       " 'eve': 1257,\n",
       " 'election': 1160,\n",
       " 'operating': 2396,\n",
       " 'san': 2928,\n",
       " 'francisco': 1434,\n",
       " 'siryn': 3069,\n",
       " 'injured': 1792,\n",
       " 'left': 1994,\n",
       " 'mentor': 2199,\n",
       " 'pete': 2483,\n",
       " 'wisdom': 3675,\n",
       " 'introduces': 1830,\n",
       " 'espionage': 1246,\n",
       " 'alleged': 214,\n",
       " 'leads': 1982,\n",
       " 'attempts': 354,\n",
       " 'continue': 792,\n",
       " 'crusade': 871,\n",
       " 'members': 2190,\n",
       " 'fake': 1329,\n",
       " 'deaths': 942,\n",
       " 'basics': 402,\n",
       " 'outside': 2425,\n",
       " 'professor': 2613,\n",
       " 'leadership': 1980,\n",
       " 'central': 615,\n",
       " 'decided': 951,\n",
       " 'break': 511,\n",
       " 'peace': 2463,\n",
       " 'work': 3689,\n",
       " 'farm': 1340,\n",
       " 'bought': 496,\n",
       " 'paychecks': 2462,\n",
       " 'teaming': 3320,\n",
       " 'reformed': 2748,\n",
       " 'threat': 3379,\n",
       " 'skornn': 3081,\n",
       " 'active': 150,\n",
       " 'nightcrawler': 2346,\n",
       " 'bishop': 451,\n",
       " 'watches': 3633,\n",
       " 'younger': 3719,\n",
       " 'carefree': 591,\n",
       " 'students': 3226,\n",
       " 'functions': 1456,\n",
       " 'sanctions': 2929,\n",
       " 'executive': 1274,\n",
       " 'xse': 3709,\n",
       " 'participated': 2453,\n",
       " '198': 31,\n",
       " 'commandos': 727,\n",
       " 'suffers': 3243,\n",
       " 'brother': 533,\n",
       " 'jay': 1861,\n",
       " 'william': 3669,\n",
       " 'stryker': 3224,\n",
       " 'foursaken': 1430,\n",
       " 'story': 3201,\n",
       " 'arc': 291,\n",
       " 'went': 3656,\n",
       " 'park': 2452,\n",
       " 'capture': 584,\n",
       " 'sent': 2995,\n",
       " 'escaping': 1245,\n",
       " 'accompanies': 134,\n",
       " 'africa': 186,\n",
       " 'assist': 334,\n",
       " 'refugees': 2751,\n",
       " 'serves': 3010,\n",
       " 'fights': 1367,\n",
       " 'hecatomb': 1619,\n",
       " 'severe': 3017,\n",
       " 'injury': 1794,\n",
       " 'decide': 950,\n",
       " 'rest': 2822,\n",
       " 'childhood': 652,\n",
       " 'home': 1667,\n",
       " 'attacked': 347,\n",
       " 'marauders': 2143,\n",
       " 'retrieve': 2839,\n",
       " 'destiny': 991,\n",
       " 'diaries': 1019,\n",
       " 'disabled': 1047,\n",
       " 'neurotoxin': 2332,\n",
       " 'uploads': 3548,\n",
       " 'got': 1524,\n",
       " 'edges': 1146,\n",
       " 'psi': 2643,\n",
       " 'shielding': 3037,\n",
       " 'mind': 2224,\n",
       " 'takes': 3304,\n",
       " 'limited': 2030,\n",
       " 'possession': 2551,\n",
       " 'aboard': 122,\n",
       " 'blackbird': 455,\n",
       " 'engaged': 1210,\n",
       " 'midair': 2220,\n",
       " 'sunfire': 3251,\n",
       " 'cripples': 860,\n",
       " 'manages': 2128,\n",
       " 'escape': 1242,\n",
       " 'battle': 406,\n",
       " 'shiro': 3040,\n",
       " 'shakes': 3025,\n",
       " 'explaining': 1290,\n",
       " 'wouldn': 3700,\n",
       " 'matter': 2167,\n",
       " 'told': 3402,\n",
       " 'ah': 200,\n",
       " 'sayin': 2945,\n",
       " 'iceman': 1700,\n",
       " 'recover': 2725,\n",
       " 'hidden': 1645,\n",
       " 'dilapidated': 1032,\n",
       " 'brewery': 516,\n",
       " 'seriously': 3005,\n",
       " 'dr': 1103,\n",
       " 'mccoy': 2171,\n",
       " 'attends': 356,\n",
       " 'injuries': 1793,\n",
       " 'evaluates': 1256,\n",
       " 'condition': 756,\n",
       " 'notes': 2357,\n",
       " 'brain': 505,\n",
       " 'scan': 2949,\n",
       " 'indicates': 1754,\n",
       " 'sluggish': 3094,\n",
       " 'non': 2350,\n",
       " 'continuous': 797,\n",
       " 'activity': 151,\n",
       " 'quickly': 2675,\n",
       " 'recovers': 2726,\n",
       " 'capable': 580,\n",
       " 'taking': 3305,\n",
       " 'divided': 1076,\n",
       " 'stand': 3165,\n",
       " 'cyclops': 897,\n",
       " 'disbands': 1053,\n",
       " 'picks': 2501,\n",
       " 'airport': 204,\n",
       " 'extremely': 1310,\n",
       " 'happy': 1583,\n",
       " 'moody': 2264,\n",
       " 'withdrawn': 3679,\n",
       " 'confronts': 767,\n",
       " 'mood': 2263,\n",
       " 'angrily': 250,\n",
       " 'blasts': 462,\n",
       " 'sky': 3086,\n",
       " 'saying': 2946,\n",
       " 'manifest': 2135,\n",
       " 'called': 560,\n",
       " 'informing': 1777,\n",
       " 'reforming': 2749,\n",
       " 'agrees': 199,\n",
       " 'arrives': 306,\n",
       " 'magneto': 2110,\n",
       " 'attacking': 349,\n",
       " 'city': 672,\n",
       " 'antique': 266,\n",
       " 'sentinels': 2998,\n",
       " 'plow': 2528,\n",
       " 'disarming': 1051,\n",
       " 'artificial': 312,\n",
       " 'magnetism': 2109,\n",
       " 'suit': 3247,\n",
       " 'giving': 1511,\n",
       " 'upper': 3549,\n",
       " 'hand': 1575,\n",
       " 'seen': 2982,\n",
       " 'bar': 394,\n",
       " 'dani': 909,\n",
       " 'disillusioned': 1064,\n",
       " 'idea': 1701,\n",
       " 'changing': 628,\n",
       " 'instead': 1807,\n",
       " 'content': 788,\n",
       " 'making': 2123,\n",
       " 'sure': 3271,\n",
       " 'dies': 1027,\n",
       " 'way': 3637,\n",
       " 'did': 1023,\n",
       " 'deal': 937,\n",
       " 'empath': 1184,\n",
       " 'receiving': 2721,\n",
       " 'anonymous': 260,\n",
       " 'tip': 3395,\n",
       " 'colorado': 708,\n",
       " 'endangering': 1201,\n",
       " 'small': 3095,\n",
       " 'town': 3416,\n",
       " 'shan': 3026,\n",
       " 'investigate': 1834,\n",
       " 'calm': 563,\n",
       " 'locals': 2047,\n",
       " 'reappears': 2706,\n",
       " 'teleporting': 3339,\n",
       " 'infernus': 1767,\n",
       " 'return': 2840,\n",
       " 'informs': 1778,\n",
       " 'roberto': 2878,\n",
       " 'trouble': 3462,\n",
       " 'result': 2824,\n",
       " 'unconscious': 3505,\n",
       " 'tricked': 3452,\n",
       " 'freeing': 1441,\n",
       " 'legion': 1998,\n",
       " 'personalities': 2481,\n",
       " 'want': 3621,\n",
       " 'locates': 2048,\n",
       " 'jail': 1855,\n",
       " 'cell': 613,\n",
       " 'stops': 3196,\n",
       " 'tells': 3343,\n",
       " 'let': 2006,\n",
       " 'refuses': 2752,\n",
       " 'll': 2043,\n",
       " 'safer': 2915,\n",
       " 'doesn': 1082,\n",
       " 'anymore': 268,\n",
       " 'leaving': 1992,\n",
       " 'unbeknownst': 3500,\n",
       " 'project': 2618,\n",
       " 'stalling': 3164,\n",
       " 'prepares': 2572,\n",
       " 'stopped': 3195,\n",
       " 'free': 1438,\n",
       " 'retreats': 2838,\n",
       " 'apologizes': 273,\n",
       " 'gets': 1496,\n",
       " 'punched': 2658,\n",
       " 'face': 1315,\n",
       " 'angry': 251,\n",
       " 'going': 1519,\n",
       " 'replies': 2796,\n",
       " 'make': 2120,\n",
       " 'useful': 3555,\n",
       " 'returns': 2843,\n",
       " 'brandishing': 508,\n",
       " 'numerous': 2364,\n",
       " 'firearms': 1383,\n",
       " 'isn': 1849,\n",
       " 'stop': 3194,\n",
       " 'pretending': 2583,\n",
       " 'earth': 1139,\n",
       " 'wants': 3623,\n",
       " 'dead': 933,\n",
       " 'upset': 3550,\n",
       " 'van': 3565,\n",
       " 'drives': 1117,\n",
       " 'away': 379,\n",
       " 'turn': 3472,\n",
       " 'badly': 387,\n",
       " 'beaten': 412,\n",
       " 'caught': 605,\n",
       " 'tries': 3454,\n",
       " 'apologize': 272,\n",
       " 'limps': 2033,\n",
       " 'ignoring': 1707,\n",
       " 'confesses': 759,\n",
       " 'feels': 1357,\n",
       " 'messed': 2208,\n",
       " 'congratulates': 768,\n",
       " 'keeping': 1906,\n",
       " 'alive': 213,\n",
       " 'matters': 2168,\n",
       " 'scott': 2959,\n",
       " 'didn': 1024,\n",
       " 'pick': 2500,\n",
       " 'understanding': 3514,\n",
       " 'allows': 223,\n",
       " 'conversation': 803,\n",
       " 'past': 2460,\n",
       " 'affiliations': 184,\n",
       " 'share': 3029,\n",
       " 'kiss': 1929,\n",
       " 'comparative': 736,\n",
       " 'purposes': 2664,\n",
       " 'interrupted': 1827,\n",
       " 'hires': 1654,\n",
       " 'teaches': 3318,\n",
       " 'course': 836,\n",
       " 'flying': 1407,\n",
       " 'natural': 2316,\n",
       " 'use': 3553,\n",
       " 'jetpacks': 1868,\n",
       " 'check': 641,\n",
       " 'works': 3694,\n",
       " 'worried': 3698,\n",
       " 'state': 3173,\n",
       " 'months': 2262,\n",
       " 'living': 2042,\n",
       " 'alien': 212,\n",
       " 'planet': 2513,\n",
       " 'empire': 1186,\n",
       " 'izzy': 1852,\n",
       " 'kane': 1899,\n",
       " 'child': 651,\n",
       " 'place': 2510,\n",
       " 'floating': 1404,\n",
       " 'volcanic': 3615,\n",
       " 'island': 1848,\n",
       " 'approached': 284,\n",
       " 'version': 3582,\n",
       " 'cage': 554,\n",
       " 'nemesis': 2327,\n",
       " 'golden': 1520,\n",
       " 'skull': 3083,\n",
       " 'timeline': 3391,\n",
       " 'steal': 3183,\n",
       " 'wealth': 3642,\n",
       " 'defeats': 967,\n",
       " 'captures': 586,\n",
       " 'opening': 2393,\n",
       " 'salvo': 2922,\n",
       " 'storyline': 3202,\n",
       " 'decides': 952,\n",
       " 'quit': 2676,\n",
       " 'live': 2040,\n",
       " 'wife': 3665,\n",
       " 'son': 3114,\n",
       " 'discover': 1054,\n",
       " 'alpha': 226,\n",
       " 'flight': 1403,\n",
       " 'program': 2616,\n",
       " 'guardians': 1559,\n",
       " 'galaxy': 1466,\n",
       " 'ultimates': 3489,\n",
       " 'chitauri': 657,\n",
       " 'heroes': 1641,\n",
       " 'presumed': 2582,\n",
       " 'dragon': 1104,\n",
       " 'eats': 1143,\n",
       " 'quasar': 2669,\n",
       " 'explodes': 1293,\n",
       " 'sold': 3107,\n",
       " 'auction': 362,\n",
       " 'mysterious': 2296,\n",
       " 'human': 1682,\n",
       " 'named': 2303,\n",
       " 'howard': 1681,\n",
       " 'mason': 2158,\n",
       " 'brings': 526,\n",
       " 'like': 2020,\n",
       " 'travels': 3445,\n",
       " 'introduced': 1829,\n",
       " 'townspeople': 3417,\n",
       " 'ritchie': 2871,\n",
       " 'redwood': 2734,\n",
       " 'ruler': 2904,\n",
       " 'discovering': 1056,\n",
       " 'people': 2471,\n",
       " 'troublesome': 3463,\n",
       " 'behavior': 420,\n",
       " 'captured': 585,\n",
       " 'awakening': 376,\n",
       " 'dungeon': 1125,\n",
       " 'prisoners': 2603,\n",
       " 'teen': 3333,\n",
       " 'bugface': 541,\n",
       " 'stages': 3161,\n",
       " 'prison': 2601,\n",
       " 'head': 1608,\n",
       " 'overthrow': 2434,\n",
       " 'smasher': 3096,\n",
       " 'arrive': 305,\n",
       " 'army': 299,\n",
       " 'possesses': 2550,\n",
       " 'bodily': 477,\n",
       " 'generate': 1483,\n",
       " 'thermo': 3364,\n",
       " 'chemical': 643,\n",
       " 'energy': 1208,\n",
       " 'release': 2775,\n",
       " 'skin': 3080,\n",
       " 'used': 3554,\n",
       " 'thrust': 3383,\n",
       " 'cause': 606,\n",
       " 'propelled': 2627,\n",
       " 'air': 203,\n",
       " 'rocket': 2886,\n",
       " 'great': 1539,\n",
       " 'heights': 1621,\n",
       " 'maneuverability': 2131,\n",
       " 'speed': 3138,\n",
       " 'direction': 1042,\n",
       " 'sheer': 3033,\n",
       " 'feet': 1358,\n",
       " 'legs': 1999,\n",
       " 'wide': 3661,\n",
       " 'variety': 3571,\n",
       " 'effects': 1151,\n",
       " 'indestructible': 1752,\n",
       " 'blast': 461,\n",
       " 'protects': 2636,\n",
       " 'harm': 1587,\n",
       " 'following': 1411,\n",
       " 'function': 1454,\n",
       " 'personal': 2480,\n",
       " 'shield': 3036,\n",
       " 'extending': 1301,\n",
       " 'encompass': 1196,\n",
       " 'shape': 3027,\n",
       " 'person': 2479,\n",
       " 'imprison': 1729,\n",
       " 'absorb': 125,\n",
       " 'kinetic': 1925,\n",
       " 'impact': 1716,\n",
       " 'supply': 3267,\n",
       " 'enabling': 1193,\n",
       " 'increase': 1744,\n",
       " 'bludgeoning': 468,\n",
       " 'power': 2559,\n",
       " 'blows': 467,\n",
       " 'create': 848,\n",
       " 'explosive': 1295,\n",
       " 'shock': 3041,\n",
       " 'waves': 3636,\n",
       " 'levels': 2010,\n",
       " 'varied': 3570,\n",
       " 'years': 3712,\n",
       " 'peak': 2464,\n",
       " 'redirect': 2733,\n",
       " 'punches': 2659,\n",
       " 'apparent': 274,\n",
       " 'life': 2017,\n",
       " 'versions': 3583,\n",
       " 'eliminated': 1168,\n",
       " 'cullings': 875,\n",
       " 'elisabeth': 1170,\n",
       " 'joshua': 1886,\n",
       " 'spared': 3129,\n",
       " 'status': 3179,\n",
       " 'mister': 2243,\n",
       " 'sinister': 3068,\n",
       " 'offered': 2374,\n",
       " 'chance': 624,\n",
       " 'elite': 1171,\n",
       " 'took': 3405,\n",
       " 'emf': 1180,\n",
       " 'alongside': 225,\n",
       " 'amazon': 235,\n",
       " 'violent': 3599,\n",
       " 'breeding': 515,\n",
       " 'pens': 2469,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = vectorizer.vocabulary_\n",
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zombies', 3728), ('zeb', 3727), ('zauriel', 3726), ('zatara', 3725), ('zatanna', 3724), ('zander', 3723), ('zachary', 3722), ('yucatan', 3721), ('yr', 3720), ('younger', 3719), ('young', 3718), ('yorkes', 3717), ('york', 3716), ('yo', 3715), ('yeti', 3714), ('yellow', 3713), ('years', 3712), ('year', 3711), ('yakuza', 3710), ('xse', 3709)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(voc.items(), key=lambda x: x[1], reverse = True)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Create the co-occurence matrix and apply svd decomposition to it.\n",
    "\n",
    "To create a token co-occurence matrix, we simply multiply the transpose of the documents/tokens matrix by the documents/token matrix\n",
    "\n",
    "* shape of X: (#doc, #tokens)\n",
    "* shape of X transpose: (#tokens, #doc)\n",
    "* shape of X transpose * X : (#tokens, #doc) * (#doc, #tokens) = (#tokens, #tokens)\n",
    "\n",
    "\n",
    "The resulting  matrix A is of size (vocab_length, vocab_length)\n",
    "\n",
    "* Use numpy [svd](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) method from the linalg module to apply SVD decomposition to A (A = U * s * V)\n",
    "  - use the todense() method to create a matrix in dense format\n",
    "  - when calling fnp.linalg.svd use the null_matrices = False option to ensures that reduced SVD is applied (rather than full SVD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3729)\n",
      "(3729, 10)\n",
      "(3729, 3729)\n"
     ]
    }
   ],
   "source": [
    "# transpose X\n",
    "Xt = X.T\n",
    "\n",
    "# multiply X with its transpose\n",
    "A = Xt.dot(X)\n",
    "\n",
    "# check the shapes\n",
    "print(X.shape)\n",
    "print(Xt.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 2]\n",
      " [0 0 0 ... 0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "# set the diagonal to zero\n",
    "A.setdiag(0)\n",
    "print(A.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non reduced SVD:\n",
      "U: (3729, 3729)\n",
      "s: (3729,)\n",
      "Vt: (3729, 3729)\n",
      "Reduced SVD:\n",
      "U: (3729, 3729)\n",
      "s: (3729,)\n",
      "Vt: (3729, 3729)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "# apply non-reduced SVD decomposition to A\n",
    "# A = U * s * Vt\n",
    "U, s, Vt = svd(A.todense(), full_matrices=True) \n",
    "\n",
    "# check the shapes\n",
    "print(\"Non reduced SVD:\")\n",
    "print(f\"U: {U.shape}\")\n",
    "print(f\"s: {s.shape}\")\n",
    "print(f\"Vt: {Vt.shape}\")\n",
    "\n",
    "# apply reduced SVD decomposition to A\n",
    "# A = U * s * Vt\n",
    "U, s, Vt = svd(A.todense(), full_matrices=False)\n",
    "\n",
    "# check the shapes\n",
    "print(\"Reduced SVD:\")\n",
    "print(f\"U: {U.shape}\")\n",
    "print(f\"s: {s.shape}\")\n",
    "print(f\"Vt: {Vt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3729, 3729)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al</th>\n",
       "      <th>mackenzie</th>\n",
       "      <th>fictional</th>\n",
       "      <th>character</th>\n",
       "      <th>appearing</th>\n",
       "      <th>american</th>\n",
       "      <th>comic</th>\n",
       "      <th>books</th>\n",
       "      <th>published</th>\n",
       "      <th>marvel</th>\n",
       "      <th>...</th>\n",
       "      <th>scar</th>\n",
       "      <th>neck</th>\n",
       "      <th>conceptual</th>\n",
       "      <th>colorist</th>\n",
       "      <th>christina</th>\n",
       "      <th>journal</th>\n",
       "      <th>eyes</th>\n",
       "      <th>gael</th>\n",
       "      <th>garcã</th>\n",
       "      <th>bernal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mackenzie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fictional</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appearing</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journal</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gael</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garcã</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 3729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           al  mackenzie  fictional  character  appearing  american  comic  \\\n",
       "al          0          0          0          0          0         0      0   \n",
       "mackenzie   0          0          0          1          1         0      0   \n",
       "fictional   0          0          0          0          0         1      0   \n",
       "character   0          1          0          0          1         0      0   \n",
       "appearing   0          1          0          1          0         0      0   \n",
       "...        ..        ...        ...        ...        ...       ...    ...   \n",
       "journal     0          2          0          2          2         0      0   \n",
       "eyes        0          1          0          1          1         0      0   \n",
       "gael        0          1          0          1          1         0      0   \n",
       "garcã       0          0          0          0          0         0      1   \n",
       "bernal      0          0          0          0          0         0      2   \n",
       "\n",
       "           books  published  marvel  ...  scar  neck  conceptual  colorist  \\\n",
       "al             0          1       0  ...     1     0           0         0   \n",
       "mackenzie      0          2       0  ...     0     0           1         0   \n",
       "fictional      1          0       0  ...     0    20           0         0   \n",
       "character      0          2       0  ...     0     0           1         0   \n",
       "appearing      0          2       0  ...     0     0           1         0   \n",
       "...          ...        ...     ...  ...   ...   ...         ...       ...   \n",
       "journal        0          4       0  ...     0     0           2         0   \n",
       "eyes           0          2       0  ...     0     0           1         0   \n",
       "gael           0          2       0  ...     0     0           1         0   \n",
       "garcã          0          1       1  ...     1     0           0         1   \n",
       "bernal         0          2       2  ...     2     0           0         2   \n",
       "\n",
       "           christina  journal  eyes  gael  garcã  bernal  \n",
       "al                 0        0     0     0      0       0  \n",
       "mackenzie          0        2     1     1      0       0  \n",
       "fictional          0        0     0     0      0       0  \n",
       "character          0        2     1     1      0       0  \n",
       "appearing          0        2     1     1      0       0  \n",
       "...              ...      ...   ...   ...    ...     ...  \n",
       "journal            0        0     2     2      0       0  \n",
       "eyes               0        2     0     1      0       0  \n",
       "gael               0        2     1     0      0       0  \n",
       "garcã              0        0     0     0      0       2  \n",
       "bernal             0        0     0     0      2       0  \n",
       "\n",
       "[3729 rows x 3729 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep the first 10 singular values\n",
    "s10 = np.array([s  if i < 10 else 0 for i,s in enumerate(s)])\n",
    "\n",
    "# Reconstruct the matrix A with the first 10 singular values\n",
    "A10 = U.dot(np.diag(s10)).dot(Vt.T)\n",
    "\n",
    "# check the shape\n",
    "print(A10.shape)\n",
    "\n",
    "# Print A and A10 as a DataFrame\n",
    "pd.DataFrame(A.todense(), index=voc, columns=voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al</th>\n",
       "      <th>mackenzie</th>\n",
       "      <th>fictional</th>\n",
       "      <th>character</th>\n",
       "      <th>appearing</th>\n",
       "      <th>american</th>\n",
       "      <th>comic</th>\n",
       "      <th>books</th>\n",
       "      <th>published</th>\n",
       "      <th>marvel</th>\n",
       "      <th>...</th>\n",
       "      <th>scar</th>\n",
       "      <th>neck</th>\n",
       "      <th>conceptual</th>\n",
       "      <th>colorist</th>\n",
       "      <th>christina</th>\n",
       "      <th>journal</th>\n",
       "      <th>eyes</th>\n",
       "      <th>gael</th>\n",
       "      <th>garcã</th>\n",
       "      <th>bernal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>-0.130410</td>\n",
       "      <td>-0.522481</td>\n",
       "      <td>0.053226</td>\n",
       "      <td>0.236261</td>\n",
       "      <td>-0.214353</td>\n",
       "      <td>-0.044951</td>\n",
       "      <td>0.176006</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>0.099147</td>\n",
       "      <td>-0.093732</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.160740</td>\n",
       "      <td>23.084403</td>\n",
       "      <td>10.808825</td>\n",
       "      <td>2.362791</td>\n",
       "      <td>-19.457889</td>\n",
       "      <td>-2.398453</td>\n",
       "      <td>3.976531</td>\n",
       "      <td>-12.591957</td>\n",
       "      <td>40.633160</td>\n",
       "      <td>3.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mackenzie</th>\n",
       "      <td>-0.217422</td>\n",
       "      <td>1.168408</td>\n",
       "      <td>0.211535</td>\n",
       "      <td>0.952388</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>-0.084423</td>\n",
       "      <td>0.305384</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136572</td>\n",
       "      <td>-5.646797</td>\n",
       "      <td>-1.281016</td>\n",
       "      <td>-0.248733</td>\n",
       "      <td>-15.388486</td>\n",
       "      <td>-7.523683</td>\n",
       "      <td>11.056087</td>\n",
       "      <td>-0.592459</td>\n",
       "      <td>8.165807</td>\n",
       "      <td>59.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fictional</th>\n",
       "      <td>0.170095</td>\n",
       "      <td>-0.785521</td>\n",
       "      <td>-0.191115</td>\n",
       "      <td>-0.060905</td>\n",
       "      <td>-0.131229</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>0.119905</td>\n",
       "      <td>-0.018667</td>\n",
       "      <td>0.056802</td>\n",
       "      <td>-0.187664</td>\n",
       "      <td>...</td>\n",
       "      <td>4.915930</td>\n",
       "      <td>-8.543045</td>\n",
       "      <td>-8.060225</td>\n",
       "      <td>9.066797</td>\n",
       "      <td>-28.651063</td>\n",
       "      <td>23.531821</td>\n",
       "      <td>-40.373609</td>\n",
       "      <td>-2.624257</td>\n",
       "      <td>-1.871770</td>\n",
       "      <td>17.479158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>-0.217422</td>\n",
       "      <td>1.168408</td>\n",
       "      <td>0.211535</td>\n",
       "      <td>0.952388</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>-0.084423</td>\n",
       "      <td>0.305384</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136572</td>\n",
       "      <td>-5.646797</td>\n",
       "      <td>-1.281016</td>\n",
       "      <td>-0.248733</td>\n",
       "      <td>-15.388486</td>\n",
       "      <td>-7.523683</td>\n",
       "      <td>11.056087</td>\n",
       "      <td>-0.592459</td>\n",
       "      <td>8.165807</td>\n",
       "      <td>59.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appearing</th>\n",
       "      <td>-0.217422</td>\n",
       "      <td>1.168408</td>\n",
       "      <td>0.211535</td>\n",
       "      <td>0.952388</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>-0.084423</td>\n",
       "      <td>0.305384</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136572</td>\n",
       "      <td>-5.646797</td>\n",
       "      <td>-1.281016</td>\n",
       "      <td>-0.248733</td>\n",
       "      <td>-15.388486</td>\n",
       "      <td>-7.523683</td>\n",
       "      <td>11.056087</td>\n",
       "      <td>-0.592459</td>\n",
       "      <td>8.165807</td>\n",
       "      <td>59.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journal</th>\n",
       "      <td>-0.434623</td>\n",
       "      <td>2.336116</td>\n",
       "      <td>0.422866</td>\n",
       "      <td>1.904281</td>\n",
       "      <td>-0.171248</td>\n",
       "      <td>-0.168803</td>\n",
       "      <td>0.610651</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.077753</td>\n",
       "      <td>0.540167</td>\n",
       "      <td>...</td>\n",
       "      <td>14.270305</td>\n",
       "      <td>-11.287148</td>\n",
       "      <td>-2.561927</td>\n",
       "      <td>-0.497480</td>\n",
       "      <td>-30.777282</td>\n",
       "      <td>-15.034466</td>\n",
       "      <td>22.106107</td>\n",
       "      <td>-1.182442</td>\n",
       "      <td>16.325255</td>\n",
       "      <td>119.529559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>-0.217422</td>\n",
       "      <td>1.168408</td>\n",
       "      <td>0.211535</td>\n",
       "      <td>0.952388</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>-0.084423</td>\n",
       "      <td>0.305384</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136572</td>\n",
       "      <td>-5.646797</td>\n",
       "      <td>-1.281016</td>\n",
       "      <td>-0.248733</td>\n",
       "      <td>-15.388486</td>\n",
       "      <td>-7.523683</td>\n",
       "      <td>11.056087</td>\n",
       "      <td>-0.592459</td>\n",
       "      <td>8.165807</td>\n",
       "      <td>59.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gael</th>\n",
       "      <td>-0.217422</td>\n",
       "      <td>1.168408</td>\n",
       "      <td>0.211535</td>\n",
       "      <td>0.952388</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>-0.084423</td>\n",
       "      <td>0.305384</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136572</td>\n",
       "      <td>-5.646797</td>\n",
       "      <td>-1.281016</td>\n",
       "      <td>-0.248733</td>\n",
       "      <td>-15.388486</td>\n",
       "      <td>-7.523683</td>\n",
       "      <td>11.056087</td>\n",
       "      <td>-0.592459</td>\n",
       "      <td>8.165807</td>\n",
       "      <td>59.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garcã</th>\n",
       "      <td>0.232188</td>\n",
       "      <td>-0.543298</td>\n",
       "      <td>-0.335489</td>\n",
       "      <td>1.335355</td>\n",
       "      <td>-0.836530</td>\n",
       "      <td>-0.174042</td>\n",
       "      <td>0.906149</td>\n",
       "      <td>-0.070226</td>\n",
       "      <td>0.238415</td>\n",
       "      <td>-0.134740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607258</td>\n",
       "      <td>-6.496423</td>\n",
       "      <td>3.536097</td>\n",
       "      <td>1.318781</td>\n",
       "      <td>-104.036011</td>\n",
       "      <td>-8.383799</td>\n",
       "      <td>-1.729620</td>\n",
       "      <td>-5.878324</td>\n",
       "      <td>29.075718</td>\n",
       "      <td>-38.325303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernal</th>\n",
       "      <td>0.464441</td>\n",
       "      <td>-1.086585</td>\n",
       "      <td>-0.670959</td>\n",
       "      <td>2.670387</td>\n",
       "      <td>-1.672554</td>\n",
       "      <td>-0.348027</td>\n",
       "      <td>1.812083</td>\n",
       "      <td>-0.140458</td>\n",
       "      <td>0.476769</td>\n",
       "      <td>-0.269467</td>\n",
       "      <td>...</td>\n",
       "      <td>1.214349</td>\n",
       "      <td>-12.984480</td>\n",
       "      <td>7.073234</td>\n",
       "      <td>2.638212</td>\n",
       "      <td>-208.044087</td>\n",
       "      <td>-16.759451</td>\n",
       "      <td>-3.457568</td>\n",
       "      <td>-11.756286</td>\n",
       "      <td>58.137287</td>\n",
       "      <td>-76.620726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 3729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 al  mackenzie  fictional  character  appearing  american  \\\n",
       "al        -0.130410  -0.522481   0.053226   0.236261  -0.214353 -0.044951   \n",
       "mackenzie -0.217422   1.168408   0.211535   0.952388  -0.085639 -0.084423   \n",
       "fictional  0.170095  -0.785521  -0.191115  -0.060905  -0.131229 -0.009147   \n",
       "character -0.217422   1.168408   0.211535   0.952388  -0.085639 -0.084423   \n",
       "appearing -0.217422   1.168408   0.211535   0.952388  -0.085639 -0.084423   \n",
       "...             ...        ...        ...        ...        ...       ...   \n",
       "journal   -0.434623   2.336116   0.422866   1.904281  -0.171248 -0.168803   \n",
       "eyes      -0.217422   1.168408   0.211535   0.952388  -0.085639 -0.084423   \n",
       "gael      -0.217422   1.168408   0.211535   0.952388  -0.085639 -0.084423   \n",
       "garcã      0.232188  -0.543298  -0.335489   1.335355  -0.836530 -0.174042   \n",
       "bernal     0.464441  -1.086585  -0.670959   2.670387  -1.672554 -0.348027   \n",
       "\n",
       "              comic     books  published    marvel  ...       scar       neck  \\\n",
       "al         0.176006  0.046005   0.099147 -0.093732  ... -11.160740  23.084403   \n",
       "mackenzie  0.305384  0.004226   0.038886  0.270177  ...   7.136572  -5.646797   \n",
       "fictional  0.119905 -0.018667   0.056802 -0.187664  ...   4.915930  -8.543045   \n",
       "character  0.305384  0.004226   0.038886  0.270177  ...   7.136572  -5.646797   \n",
       "appearing  0.305384  0.004226   0.038886  0.270177  ...   7.136572  -5.646797   \n",
       "...             ...       ...        ...       ...  ...        ...        ...   \n",
       "journal    0.610651  0.008425   0.077753  0.540167  ...  14.270305 -11.287148   \n",
       "eyes       0.305384  0.004226   0.038886  0.270177  ...   7.136572  -5.646797   \n",
       "gael       0.305384  0.004226   0.038886  0.270177  ...   7.136572  -5.646797   \n",
       "garcã      0.906149 -0.070226   0.238415 -0.134740  ...   0.607258  -6.496423   \n",
       "bernal     1.812083 -0.140458   0.476769 -0.269467  ...   1.214349 -12.984480   \n",
       "\n",
       "           conceptual  colorist   christina    journal       eyes       gael  \\\n",
       "al          10.808825  2.362791  -19.457889  -2.398453   3.976531 -12.591957   \n",
       "mackenzie   -1.281016 -0.248733  -15.388486  -7.523683  11.056087  -0.592459   \n",
       "fictional   -8.060225  9.066797  -28.651063  23.531821 -40.373609  -2.624257   \n",
       "character   -1.281016 -0.248733  -15.388486  -7.523683  11.056087  -0.592459   \n",
       "appearing   -1.281016 -0.248733  -15.388486  -7.523683  11.056087  -0.592459   \n",
       "...               ...       ...         ...        ...        ...        ...   \n",
       "journal     -2.561927 -0.497480  -30.777282 -15.034466  22.106107  -1.182442   \n",
       "eyes        -1.281016 -0.248733  -15.388486  -7.523683  11.056087  -0.592459   \n",
       "gael        -1.281016 -0.248733  -15.388486  -7.523683  11.056087  -0.592459   \n",
       "garcã        3.536097  1.318781 -104.036011  -8.383799  -1.729620  -5.878324   \n",
       "bernal       7.073234  2.638212 -208.044087 -16.759451  -3.457568 -11.756286   \n",
       "\n",
       "               garcã      bernal  \n",
       "al         40.633160    3.379310  \n",
       "mackenzie   8.165807   59.781745  \n",
       "fictional  -1.871770   17.479158  \n",
       "character   8.165807   59.781745  \n",
       "appearing   8.165807   59.781745  \n",
       "...              ...         ...  \n",
       "journal    16.325255  119.529559  \n",
       "eyes        8.165807   59.781745  \n",
       "gael        8.165807   59.781745  \n",
       "garcã      29.075718  -38.325303  \n",
       "bernal     58.137287  -76.620726  \n",
       "\n",
       "[3729 rows x 3729 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(A10, index=voc, columns=voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6 (PROVIDED):** Define a function which returns the similarity between 2 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "token2int = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(embeddings, word1, word2):\n",
    "  if word1 in vocab and word2 in vocab:\n",
    "    v1 = embeddings[token2int[word1]].reshape(1, -1)  \n",
    "    v2 = embeddings[token2int[word2]].reshape(1, -1)\n",
    "    return cosine_similarity(v1, v2)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** Use the function given in Exercise 6 to measure the similarity between\n",
    "- escape and fictional\n",
    "- canada and handbook\n",
    "- escape and captivity\n",
    "\n",
    "You might need to modify that part of the function which defines vocab and token2int to make it compatible with the way you named your vectorizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9362681251764143\n",
      "0.5908997499020893\n",
      "0.47912100855108686\n"
     ]
    }
   ],
   "source": [
    "print(similarity(A, \"escape\", \"fictional\"))\n",
    "print(similarity(A, \"canada\", \"handbook\"))\n",
    "print(similarity(A, \"escape\", \"captivity\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** Clean the corpus \n",
    "\n",
    "* Store the content of the 'Text\" column into a string   \n",
    "    **Pandas CS, \"Extracting all text from a colum\"**\n",
    "* Tokenize the string into words   \n",
    "    **NLTK CS**\n",
    "* Print out the first and the last 10 words of your list of tokens. Do you see tokens that may not be useful for learning word representations ?\n",
    "* Lower case all tokens and remove all tokens that contains characters that are not letters (OPTIONAL)   \n",
    "    **NLTK CS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = str.join(\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = word_tokenize(\"This is a test sentence\", language=\"english\")\n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "\n",
    "# Print first and last 10 tokens\n",
    "print(tokens[:10])\n",
    "print(tokens[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a frequency distribution (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** Create a frequency distribution from the list of tokens created in the previous exercise. Print out the 10 most and least frequent tokens.   \n",
    "   **lexical semantics and stats_and_visu CS**\n",
    "* Create a frequency distribution by iterating over the list of token while incrementing each token frequency accordingly\n",
    "* Sort the tokens by decreasing frequency into a list\n",
    "* Print out the first and last 10 tokens of this list (which tokens are most and least frequent ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the corpus to a list of integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:** Convert the list of tokens created in Exercise 2 (corpus cleaning) into a list of integers\n",
    "\n",
    "* Create a dictionary mapping each token to a distinct integer (Cf. Lexical Semantics CS)\n",
    "* Use this dictionary to convert each token from your cleaned corpus (Exercise 2) into an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of co-occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11:** In the previous exercise, you created a list of integers where each integer is the identifier for the corresponding token in your cleaned up corpus. Iterate over that list and for each \"integer token\" *i*:\n",
    "\n",
    "* get the neihbours of *i* within a window of size 5 (only looking at the right side of *i*)\n",
    "* store these neihbours in a dictionary of coocurrences of the form {(i,j):f,} where *(i,j)* are neighbours and *f* is the frequency of the co-occurence \n",
    "* Sort co-occurences using integer order i.e., if the neighbour *n* is represented by an identifier smaller than *i*, store the co-occurence as *(n,i)*, otherwise as *(i,n)* .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the SVD decomposition of the Co-occurence Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** Compute the  SVD decomposition of the word co-occurence matrix you just created\n",
    "\n",
    "* Create a matrix A of size (vocab_length, vocab_length)\n",
    "* Fill each cell *(i,j)* in this matrix with the frequency the co-occurrence between *i* and *j*\n",
    "* Use numpy [svd](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) method from the linalg module\n",
    "* full_matrices = False ensures that reduced SVD is applied (rather than full SVD)\n",
    "\n",
    "A = U * s * V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13 (PROVIDED):** Define a function which outputs the neighbours of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reverse_vocab = {j: i for i, j in token2int.items()}\n",
    "\n",
    "def most_similar(embedding, word, n=10):\n",
    "  if word in vocab:\n",
    "    v = embedding[token2int[word]].reshape(1, -1)\n",
    "    scores = cosine_similarity(v, embedding).reshape(-1)\n",
    "    result = []\n",
    "\n",
    "    # argsort gives n-best scores\n",
    "    for i in reversed(scores.argsort()[-n:]):\n",
    "      result.append((reverse_vocab[i], scores[i]))\n",
    "    return result\n",
    "\n",
    "print(most_similar(U, 'fictional'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(most_similar(U, 'handbook'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3de7a084b318d7b8bf96005cb5db4da14a27f60df0465391ef48a4c336f03bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
