{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading files from a directory into a panda dataframe**\n",
    "\n",
    "* the  [load_files](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html) takes as input a directory in which the immediate subdirectories are category names for the text files they contain \n",
    "\n",
    "```\n",
    "DIR/\n",
    " category_1/\n",
    "    file_1.txt file_2.txt … file_42.txt\n",
    " category_2/\n",
    "    file_43.txt file_44.txt …\n",
    "```\n",
    "\n",
    "* the load_files method from sklearn \n",
    "recursively uploads all files in a directory and return a dictionary object with attributes:\n",
    "   - \"data\" whose value is the text content of the input files and \n",
    "   - \"target_names\" whose value is the names of the subdirectory containing the text files. \n",
    "* the code below uses this method to extract the content and categories of the text files contained in the ../data/bbc/ directory and to store them into a pandas frame with headers 'text' and 'label' respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business  entertainment  politics  README.TXT  sport  tech\r\n"
     ]
    }
   ],
   "source": [
    "!ls bbc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tate &amp; Lyle boss bags top award\\n\\nTate &amp; Lyle...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo 2 sells five million copies\\n\\nMicrosoft ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSPs hear renewed climate warning\\n\\nClimate c...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pavey focuses on indoor success\\n\\nJo Pavey wi...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tories reject rethink on axed MP\\n\\nSacked MP ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          label\n",
       "0  Tate & Lyle boss bags top award\\n\\nTate & Lyle...       business\n",
       "1  Halo 2 sells five million copies\\n\\nMicrosoft ...  entertainment\n",
       "2  MSPs hear renewed climate warning\\n\\nClimate c...       politics\n",
       "3  Pavey focuses on indoor success\\n\\nJo Pavey wi...          sport\n",
       "4  Tories reject rethink on axed MP\\n\\nSacked MP ...           tech"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "# Loading all files in \"dir\" directory into a pandas dataframe\n",
    "DATA_DIR = \"bbc/\"\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\")\n",
    "df = pd.DataFrame(list(zip(data['data'], data['target_names'])), columns=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder: python zip**\n",
    "- takes two lists e.g.,  ['a','b'] and [1,4] \n",
    "- returns a dictionnary with the elements of the first list as keys and of the second as values e.g.,\n",
    "{'a':1, 'b':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sravan': 23, 'ojaswi': 21, 'rohith': 32, 'gnanesh': 11, 'bobby': 23}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list with student name\n",
    "name = ['sravan', 'ojaswi', 'rohith', 'gnanesh', 'bobby']\n",
    " \n",
    "# create a list with student age\n",
    "age = [23, 21, 32, 11, 23]\n",
    " \n",
    "# using dict method with zip()\n",
    "dict(zip(name, age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting a corpus of texts into a tf-idf matrix**\n",
    "* the input is our corpus, a list of texts\n",
    "* we can specify how the text is tokenised and whether stop-words are removed\n",
    "* the output is a matrix where each row is a text and each column is a token. The cells of the matrix contain the tf-idf score of the token in that text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "corpus = ['Apples and pears are fruit','A pear is a fruit','dogs and cats are animal','a cat is an animal']\n",
    "\n",
    "from nltk import word_tokenize\n",
    "# Create a TFIDF vectorizer to convert convert words to vectors\n",
    "vectorizer = TfidfVectorizer(max_features=10,\n",
    "                                       use_idf=True,\n",
    "                                       stop_words='english',\n",
    "                                       tokenizer=nltk.word_tokenize)\n",
    "# Apply the vectorizer to the input texts\n",
    "M = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n"
     ]
    }
   ],
   "source": [
    "# the output matrix contains 4 rows, one for each input document \n",
    "# and 5 columns as we set the max nb of features to 5\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing the features used by the clustering algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animal', 'apples', 'cat', 'cats', 'dogs', 'fruit', 'pear', 'pears']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering** \n",
    "\n",
    "[KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "* we just input the tf-idf matrix (the representation of the input texts) to a KMeans clustering model\n",
    "* the \"fit\" method fits the data i.e., aims to find the best set of clusters for it\n",
    "* n_init: the number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2, n_init=5, random_state=3425)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Create a KMeans clustering model\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=5, verbose=0, random_state=3425)\n",
    "# Apply the clustering model on the tf-idf matrix (the features)\n",
    "km.fit(M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing out clustering results**\n",
    "* You can view which item belongs to which cluster using the labels_ attribute\n",
    "* If you want to use the predicted cluster labels eg for viewing (to compare with the ground truth labels) you need to explicitely store these into a list as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the predicted labels\n",
    "predicted_labels = km.labels_\n",
    "# Store the predicted clusters into a list\n",
    "predicted_labels = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing clustering evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fruit', 'fruit', 'animals', 'animals']\n",
      "[1 1 0 0]\n",
      "Homogeneity: 1.000\n",
      "Completeness: 1.000\n",
      "V-measure: 1.000\n",
      "Adjusted Rand-Index: 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Show ground truth labels (if available)\n",
    "labels = [\"fruit\",\"fruit\",\"animals\",\"animals\"]\n",
    "print( labels)\n",
    "# Show predicted labels\n",
    "print( km.labels_)\n",
    "# Compute and show evaluation scores\n",
    "# When a ground truth is available\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "# When no ground truth is available\n",
    "#print(\"Silhouette Coefficient: %0.3f\"\n",
    "#      % metrics.silhouette_score(tfidf_matrix, km.labels_, sample_size=1000))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing out the number of items per clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First store documents, labels and cluster labels into a Pandas datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apples and pears are fruit</td>\n",
       "      <td>fruit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A pear is a fruit</td>\n",
       "      <td>fruit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dogs and cats are animal</td>\n",
       "      <td>animals</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a cat is an animal</td>\n",
       "      <td>animals</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text    label  cluster\n",
       "0  Apples and pears are fruit    fruit        1\n",
       "1           A pear is a fruit    fruit        1\n",
       "2    dogs and cats are animal  animals        0\n",
       "3          a cat is an animal  animals        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'text':corpus,'label':labels,'cluster':km.labels_}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then count the number of each occurrence in the cluster column (= the number of documents for each cluster label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2\n",
       "0    2\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the top tokens of each cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b76cae92b866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# terms maps a vectorizer index to the corresponding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# for each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Top terms per cluster:\")\n",
    "# get the number of clusters\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "# get the cluster center of each cluster \n",
    "# argsort() return the index of each dimension in the cluster center and sort them in increasing value order\n",
    "# [:, ::-1] reverts the argsort() list to place the indices with highest value first (decreasing order)\n",
    "order_centroids = km.cluster_centers_.argsort()[:]\n",
    "\n",
    "# terms maps a vectorizer index to the corresponding token\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# for each cluster\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    # print out the token of the centroid (order by decreasing tf-idf value)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3de7a084b318d7b8bf96005cb5db4da14a27f60df0465391ef48a4c336f03bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
